{"cells":[{"cell_type":"markdown","metadata":{"id":"BKueD3etSvyt"},"source":["# EfficientNet_B4 Classifier Training\n","\n","このノートブックはNFNetモデルの訓練を実行するためのものです。PyTorch Lightningを使用した学習フレームワークで、転移学習による画像分類を行います。"]},{"cell_type":"markdown","metadata":{"id":"ejvXESjtSvyt"},"source":["## Google Driveのマウント"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24022,"status":"ok","timestamp":1747396446763,"user":{"displayName":"土倉恵一郎","userId":"13053641895557367934"},"user_tz":-540},"id":"kAL5Z5BNSvyu","outputId":"a6768f3c-4e19-4611-f1a1-b06029d2a8d2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Google Colab環境を検出しました。\n","Mounted at /content/drive\n","Moved to: /content/drive/MyDrive/NFNet_Classifier_pretrained\n","現在のディレクトリ: /content/drive/MyDrive/NFNet_Classifier_pretrained\n","プロジェクトディレクトリ: /content/drive/MyDrive/NFNet_Classifier_pretrained\n","Pythonパスにsrcを追加: True\n","Pythonパスにconfigsを追加: True\n"]}],"source":["import os\n","import sys\n","\n","# Google Colab環境かどうかを判定\n","IN_COLAB = 'google.colab' in str(get_ipython())\n","\n","if IN_COLAB:\n","    print(\"Google Colab環境を検出しました。\")\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    # プロジェクトディレクトリに移動\n","    project_dir = '/content/drive/MyDrive/NFNet_Classifier_pretrained'\n","    # %cd はノートブックのセルマジックなので、os.chdirを使用\n","    if os.getcwd() != project_dir:\n","        os.chdir(project_dir)\n","        print(f\"Moved to: {os.getcwd()}\")\n","    # srcディレクトリをパスに追加 (main.pyと同じ階層にある場合)\n","    # main.pyがプロジェクトルートにあるため、srcは不要かもしれないが念のため\n","    src_dir = os.path.join(project_dir, 'src')\n","    if src_dir not in sys.path:\n","        sys.path.insert(0, src_dir)\n","    # configsディレクトリもパスに追加 (config_utilsのため)\n","    configs_dir = os.path.join(project_dir, 'configs')\n","    if configs_dir not in sys.path:\n","        sys.path.insert(0, configs_dir)\n","else:\n","    print(\"ローカル環境を検出しました。\")\n","    # ローカルのプロジェクトディレクトリを設定\n","    project_dir = 'J:/マイドライブ/NFNet_Classifier_pretrained'\n","    # カレントディレクトリがプロジェクトディレクトリでない場合は移動\n","    if os.getcwd() != os.path.abspath(project_dir):\n","        os.chdir(project_dir)\n","        print(f\"Moved to: {os.getcwd()}\")\n","    # srcディレクトリをパスに追加\n","    src_dir = os.path.join(project_dir, 'src')\n","    if src_dir not in sys.path:\n","        sys.path.insert(0, src_dir)\n","    # configsディレクトリもパスに追加\n","    configs_dir = os.path.join(project_dir, 'configs')\n","    if configs_dir not in sys.path:\n","        sys.path.insert(0, configs_dir)\n","\n","print(f\"現在のディレクトリ: {os.getcwd()}\")\n","print(f\"プロジェクトディレクトリ: {project_dir}\")\n","print(f\"Pythonパスにsrcを追加: {src_dir in sys.path}\")\n","print(f\"Pythonパスにconfigsを追加: {configs_dir in sys.path}\")\n"]},{"cell_type":"markdown","metadata":{"id":"CXOntyfISvyu"},"source":["## 必要なライブラリのインストール"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":67053,"status":"ok","timestamp":1747396513819,"user":{"displayName":"土倉恵一郎","userId":"13053641895557367934"},"user_tz":-540},"id":"A-aYt6TOSvyu","outputId":"e2e9985d-7ea5-4342-c685-a90a2cf357df"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting lightning\n","  Downloading lightning-2.5.1.post0-py3-none-any.whl.metadata (39 kB)\n","Collecting torchmetrics\n","  Downloading torchmetrics-1.7.1-py3-none-any.whl.metadata (21 kB)\n","Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (1.0.15)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n","Requirement already satisfied: PyYAML\u003c8.0,\u003e=5.4 in /usr/local/lib/python3.11/dist-packages (from lightning) (6.0.2)\n","Requirement already satisfied: fsspec\u003c2026.0,\u003e=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]\u003c2026.0,\u003e=2022.5.0-\u003elightning) (2025.3.2)\n","Collecting lightning-utilities\u003c2.0,\u003e=0.10.0 (from lightning)\n","  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n","Requirement already satisfied: packaging\u003c25.0,\u003e=20.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (24.2)\n","Requirement already satisfied: torch\u003c4.0,\u003e=2.1.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (2.6.0+cu124)\n","Requirement already satisfied: tqdm\u003c6.0,\u003e=4.57.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (4.67.1)\n","Requirement already satisfied: typing-extensions\u003c6.0,\u003e=4.4.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (4.13.2)\n","Collecting pytorch-lightning (from lightning)\n","  Downloading pytorch_lightning-2.5.1.post0-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: numpy\u003e1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (2.0.2)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm) (0.21.0+cu124)\n","Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm) (0.31.2)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm) (0.5.3)\n","Requirement already satisfied: pandas\u003e=1.2 in /usr/local/lib/python3.11/dist-packages (from seaborn) (2.2.2)\n","Requirement already satisfied: matplotlib!=3.6.1,\u003e=3.4 in /usr/local/lib/python3.11/dist-packages (from seaborn) (3.10.0)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]\u003c2026.0,\u003e=2022.5.0-\u003elightning) (3.11.15)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities\u003c2.0,\u003e=0.10.0-\u003elightning) (75.2.0)\n","Requirement already satisfied: contourpy\u003e=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,\u003e=3.4-\u003eseaborn) (1.3.2)\n","Requirement already satisfied: cycler\u003e=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,\u003e=3.4-\u003eseaborn) (0.12.1)\n","Requirement already satisfied: fonttools\u003e=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,\u003e=3.4-\u003eseaborn) (4.58.0)\n","Requirement already satisfied: kiwisolver\u003e=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,\u003e=3.4-\u003eseaborn) (1.4.8)\n","Requirement already satisfied: pillow\u003e=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,\u003e=3.4-\u003eseaborn) (11.2.1)\n","Requirement already satisfied: pyparsing\u003e=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,\u003e=3.4-\u003eseaborn) (3.2.3)\n","Requirement already satisfied: python-dateutil\u003e=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,\u003e=3.4-\u003eseaborn) (2.9.0.post0)\n","Requirement already satisfied: pytz\u003e=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas\u003e=1.2-\u003eseaborn) (2025.2)\n","Requirement already satisfied: tzdata\u003e=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas\u003e=1.2-\u003eseaborn) (2025.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch\u003c4.0,\u003e=2.1.0-\u003elightning) (3.18.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch\u003c4.0,\u003e=2.1.0-\u003elightning) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch\u003c4.0,\u003e=2.1.0-\u003elightning) (3.1.6)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch\u003c4.0,\u003e=2.1.0-\u003elightning)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch\u003c4.0,\u003e=2.1.0-\u003elightning)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch\u003c4.0,\u003e=2.1.0-\u003elightning)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch\u003c4.0,\u003e=2.1.0-\u003elightning)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch\u003c4.0,\u003e=2.1.0-\u003elightning)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch\u003c4.0,\u003e=2.1.0-\u003elightning)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch\u003c4.0,\u003e=2.1.0-\u003elightning)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch\u003c4.0,\u003e=2.1.0-\u003elightning)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch\u003c4.0,\u003e=2.1.0-\u003elightning)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch\u003c4.0,\u003e=2.1.0-\u003elightning) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch\u003c4.0,\u003e=2.1.0-\u003elightning) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch\u003c4.0,\u003e=2.1.0-\u003elightning) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch\u003c4.0,\u003e=2.1.0-\u003elightning)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch\u003c4.0,\u003e=2.1.0-\u003elightning) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch\u003c4.0,\u003e=2.1.0-\u003elightning) (1.13.1)\n","Requirement already satisfied: mpmath\u003c1.4,\u003e=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1-\u003etorch\u003c4.0,\u003e=2.1.0-\u003elightning) (1.3.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub-\u003etimm) (2.32.3)\n","Requirement already satisfied: aiohappyeyeballs\u003e=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-\u003efsspec[http]\u003c2026.0,\u003e=2022.5.0-\u003elightning) (2.6.1)\n","Requirement already satisfied: aiosignal\u003e=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-\u003efsspec[http]\u003c2026.0,\u003e=2022.5.0-\u003elightning) (1.3.2)\n","Requirement already satisfied: attrs\u003e=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-\u003efsspec[http]\u003c2026.0,\u003e=2022.5.0-\u003elightning) (25.3.0)\n","Requirement already satisfied: frozenlist\u003e=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-\u003efsspec[http]\u003c2026.0,\u003e=2022.5.0-\u003elightning) (1.6.0)\n","Requirement already satisfied: multidict\u003c7.0,\u003e=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-\u003efsspec[http]\u003c2026.0,\u003e=2022.5.0-\u003elightning) (6.4.3)\n","Requirement already satisfied: propcache\u003e=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-\u003efsspec[http]\u003c2026.0,\u003e=2022.5.0-\u003elightning) (0.3.1)\n","Requirement already satisfied: yarl\u003c2.0,\u003e=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-\u003efsspec[http]\u003c2026.0,\u003e=2022.5.0-\u003elightning) (1.20.0)\n","Requirement already satisfied: six\u003e=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil\u003e=2.7-\u003ematplotlib!=3.6.1,\u003e=3.4-\u003eseaborn) (1.17.0)\n","Requirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2-\u003etorch\u003c4.0,\u003e=2.1.0-\u003elightning) (3.0.2)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.11/dist-packages (from requests-\u003ehuggingface_hub-\u003etimm) (3.4.2)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.11/dist-packages (from requests-\u003ehuggingface_hub-\u003etimm) (3.10)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests-\u003ehuggingface_hub-\u003etimm) (2.4.0)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests-\u003ehuggingface_hub-\u003etimm) (2025.4.26)\n","Downloading lightning-2.5.1.post0-py3-none-any.whl (819 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.0/819.0 kB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torchmetrics-1.7.1-py3-none-any.whl (961 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m961.5/961.5 kB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n","Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m133.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m99.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m114.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pytorch_lightning-2.5.1.post0-py3-none-any.whl (823 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.1/823.1 kB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics, pytorch-lightning, lightning\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed lightning-2.5.1.post0 lightning-utilities-0.14.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pytorch-lightning-2.5.1.post0 torchmetrics-1.7.1\n"]}],"source":["# requirements.txtからインストール\n","# !pip install torch torchvision pytorch-lightning torchmetrics PyYAML scikit-learn pandas\n","! pip install lightning torchmetrics timm seaborn"]},{"cell_type":"markdown","metadata":{"id":"jmMDBUz7Svyu"},"source":["## GPUの確認"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3221,"status":"ok","timestamp":1747396517042,"user":{"displayName":"土倉恵一郎","userId":"13053641895557367934"},"user_tz":-540},"id":"zNZqVM0NSvyu","outputId":"722603d9-ee2b-4c2b-edab-df23a6399a11"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fri May 16 11:55:14 2025       \n","+-----------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n","|-----------------------------------------+------------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                        |               MIG M. |\n","|=========================================+========================+======================|\n","|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n","| N/A   32C    P0             48W /  400W |       0MiB /  40960MiB |      0%      Default |\n","|                                         |                        |             Disabled |\n","+-----------------------------------------+------------------------+----------------------+\n","                                                                                         \n","+-----------------------------------------------------------------------------------------+\n","| Processes:                                                                              |\n","|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n","|        ID   ID                                                               Usage      |\n","|=========================================================================================|\n","|  No running processes found                                                             |\n","+-----------------------------------------------------------------------------------------+\n","CUDA利用可能: True\n","利用可能なGPU数: 1\n","現在のGPU: NVIDIA A100-SXM4-40GB\n"]}],"source":["!nvidia-smi\n","\n","import torch\n","print(f\"CUDA利用可能: {torch.cuda.is_available()}\")\n","print(f\"利用可能なGPU数: {torch.cuda.device_count()}\")\n","if torch.cuda.is_available():\n","    print(f\"現在のGPU: {torch.cuda.get_device_name(0)}\")"]},{"cell_type":"markdown","metadata":{"id":"5qRspzfUSvyv"},"source":["## データセットの確認（オプション）"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TDRREmebSvyv"},"outputs":[],"source":["# # データセットの構造確認（オプション）\n","# !ls -la /content/drive/MyDrive/NFNet_Classifier_pretrained/nasdaq100_15m/train\n","# # 各クラスの画像数を確認\n","# !find /content/drive/MyDrive/NFNet_Classifier_pretrained/nasdaq100_15m/train -type f | grep -v \"/__\" | sort | cut -d/ -f8 | uniq -c\n","# !find /content/drive/MyDrive/NFNet_Classifier_pretrained/nasdaq100_15m/test -type f | grep -v \"/__\" | sort | cut -d/ -f8 | uniq -c"]},{"cell_type":"markdown","metadata":{"id":"ouV1lwOISvyv"},"source":["## 設定ファイルの確認と編集（必要に応じて）"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":875,"status":"ok","timestamp":1747396517924,"user":{"displayName":"土倉恵一郎","userId":"13053641895557367934"},"user_tz":-540},"id":"muEkxJTbSvyv","outputId":"14a6c93e-bbce-485b-a527-9fda8667e546"},"outputs":[{"name":"stdout","output_type":"stream","text":["使用する設定ファイル: /content/drive/MyDrive/NFNet_Classifier_pretrained/configs/config_for_google_colab.yaml\n","--- 設定ファイル内容 ---\n","# モデルモード ('single' または 'multi')\n","model_mode: single           # モデルの動作モード\n","# モデルアーキテクチャ名 (ログ/チェックポイントのディレクトリ名に使用)\n","model_architecture_name: efficientnet_b4  # 使用するモデルアーキテクチャ\n","\n","# --- 転移学習戦略設定 ---\n","# 段階的凍結解除の使用有無 (true: 段階的凍結解除, false: ステージ毎差分学習率)\n","use_progressive_unfreezing: false\n","# 段階的ファインチューニング設定 (use_progressive_unfreezing: true の場合のみ有効)\n","auto_unfreeze:\n","  stage1_epoch: 20    # ステージ1の凍結解除エポック\n","  stage2_epoch: 30    # ステージ2の凍結解除エポック\n","  stage3_epoch: 40    # ステージ3の凍結解除エポック\n","\n","# --- 学習率設定 ---\n","# 最適化されたパラメータ\n","lr_head: 0.0022754797344858332    # ヘッド部分の学習率\n","lr_backbone: 0.0003651232342099075 # バックボーン基本学習率\n","lr_decay_rate: 0.397981145024631   # 層ごとの学習率減衰率\n","scheduler: cosine      # コサインスケジューリングを使用\n","\n","# --- NFNetの勾配クリッピング設定 ---\n","# 最適化されたパラメータ\n","use_agc: false         # AGC (Adaptive Gradient Clipping) の使用有無\n","agc_clip_factor: 0.05449588573832388  # AGCのクリップ係数\n","agc_eps: 1e-3          # AGCの安定化係数\n","\n","# --- その他の学習設定 ---\n","batch_size: 40         # バッチサイズ (最適化されたパラメータ)\n","max_epochs: 100         # 総エポック数\n","\n","# --- 損失関数の重み ---\n","aux_loss_weight: 0.2587019580535172  # 補助損失の重み (最適化されたパラメータ)\n","\n","# --- オプティマイザ設定 ---\n","weight_decay: 0.06361308055294002  # 重み減衰係数 (最適化されたパラメータ)\n","\n","# --- トレーナー設定 ---\n","precision: 16-mixed         # 混合精度計算 (メモリ使用量削減と計算速度向上のため)\n","accumulate_grad_batches: 2    # 勾配累積ステップ数\n","early_stopping_patience: 10   # 改善が見られなかった時の早期停止エポック数\n","log_every_n_steps: 50         # ログ記録頻度（ステップ単位）\n","# Google Colab向け設定\n","use_gradient_checkpointing: true  # メモリ使用量を削減するための勾配チェックポイント機能\n","\n","# --- ハードウェア設定 ---\n","force_gpu: false              # GPUを強制使用するか否か (自動検出に任せる)\n","force_cpu: false              # CPUを強制使用するか否か\n","num_workers: 4                # データローダーのワーカ数 (Windowsでは注意)\n","persistent_workers: true      # ワーカープロセスの永続化有無 (データローディング高速化)\n","pin_memory: true              # データローダーのpin_memory使用有無　\n","prefetch_factor: 2            # プリフェッチ係数\n","reasoning_dim: 3              # 推論時の出力次元数\n","\n","# --- データセット設定 ---\n","num_folds: 5                # データセットの分割数\n","fold: 0                     # 使用するフォールド番号（0から num_folds-1）\n","seed: 42                    # 乱数シード\n","image_size: 380             # 画像リサイズサイズ (EfficientNet_B4推奨サイズ)\n","# データセット情報 (可視化用)\n","class_names: \n","  - Sell\n","  - Buy\n","  - Hold    # クラス名リスト\n","dataset_mean: \n","  - 0.485\n","  - 0.456\n","  - 0.406       # ImageNet平均値 (チャンネル毎)\n","dataset_std: \n","  - 0.229\n","  - 0.224\n","  - 0.225         # ImageNet標準偏差 (チャンネル毎)\n","\n","# --- モデル詳細設定 ---\n","model:\n","  type: efficientnet_b4   # 使用するモデルタイプ\n","  drop_path_rate: 0.20889964802961225  # ドロップパス率 (最適化されたパラメータ)\n","  classifier_dropout1: 0.3  # 分類器の最初のドロップアウト率\n","  classifier_dropout2: 0.2  # 分類器の2番目のドロップアウト率\n","\n","# --- データディレクトリ設定 (Google Colab) ---\n","# プロジェクトルートディレクトリ\n","base_dir: /content/drive/MyDrive/NFNet_Classifier_pretrained\n","# 入力データディレクトリ\n","data_dir: /content/drive/MyDrive/NFNet_Classifier_pretrained/data\n","# ログ保存ディレクトリ\n","logs_dir: /content/drive/MyDrive/NFNet_Classifier_pretrained/logs\n","# チェックポイント保存先ディレクトリ\n","checkpoint_dir: /content/drive/MyDrive/NFNet_Classifier_pretrained/checkpoints\n","\n","# --- 複数銘柄の設定 ---\n","# 利用可能な全銘柄リスト\n","symbols:\n","  - nasdaq100\n","  - GER30\n","  - US30\n","# 各銘柄のデータディレクトリ設定\n","nasdaq100_dir: /content/drive/MyDrive/NFNet_Classifier_pretrained/nasdaq100_15m_winsize40\n","GER30_dir: /content/drive/MyDrive/NFNet_Classifier_pretrained/GER30_15m_winsize40\n","US30_dir: /content/drive/MyDrive/NFNet_Classifier_pretrained/US30_15m_winsize40\n","\n","# --- デバッグ・再開設定 ---\n","check_data: false             # データチェックの有無\n","debug: false                  # デバッグモードの有無\n","gpu_debug: false              # GPUデバッグモードの有無\n","# resume_from_checkpoint: false # チェックポイントからの再開有無\n","resume_from_checkpoint: /content/drive/MyDrive/NFNet_Classifier_pretrained/checkpoints/singlemodal/efficientnet_b4_trial24_val_f1-val_f1=0.7180_val_loss-val_loss=0.5636_lrh2.3e-03_lrb3.7e-04.ckpt  # チェックポイントファイルのパス（ここを変更）\n","\n","# --- 時系列データ設定 ---\n","timeseries:\n","  # 使用する特徴量のカラム名リスト\n","  feature_columns:\n","    - PZO\n","    - TMF\n","    - diff\n","    - Williams_4\n","    - MFI_4\n","    - '%SD'\n","  # 時系列特徴量の次元数 (feature_columnsの数と一致させる)\n","  feature_dim: 6\n","  # ウィンドウサイズ (シーケンス長)\n","  window_size: 40\n","\n","----------------------\n"]}],"source":["# 設定ファイルの内容確認\n","import yaml\n","import os\n","import platform\n","\n","# 環境に応じた設定ファイルパスを設定\n","if IN_COLAB:\n","    config_filename = 'config_for_google_colab.yaml'\n","else:\n","    config_filename = 'config.yaml' # ローカル用の設定ファイル\n","\n","config_path = os.path.join(project_dir, 'configs', config_filename)\n","print(f\"使用する設定ファイル: {config_path}\")\n","\n","# 設定ファイルの内容確認\n","try:\n","    with open(config_path, 'r', encoding='utf-8') as f:\n","        print(\"--- 設定ファイル内容 ---\")\n","        print(f.read())\n","        print(\"----------------------\")\n","except FileNotFoundError:\n","    print(f\"エラー: 設定ファイル {config_path} が見つかりません。パスを確認してください。\")\n","# 広範な例外捕捉は避ける (例: yaml.YAMLError など、より具体的な例外を捕捉する)\n","except yaml.YAMLError as e:\n","    print(f\"設定ファイルの解析中にエラーが発生しました: {e}\")\n","except IOError as e:\n","    print(f\"設定ファイルの読み込み中にI/Oエラーが発生しました: {e}\")\n","\n","# --- 注意 ---\n","# 設定の変更は直接YAMLファイルを編集するか、main.py側で行います。\n","# このノートブックでは設定の読み込み確認のみを行います。"]},{"cell_type":"markdown","metadata":{"id":"YkiA_EhmSvyv"},"source":["## Windows環境での注意事項\n","\n","Windows環境では、Pythonのマルチプロセッシングの仕組み上の制約から、`num_workers` を0以外に設定するとエラーが発生しやすくなります。これは主に以下の理由によります：\n","\n","- **プロセス生成方法の違い**: LinuxなどのUnix系OSでは、フォーク（`fork`）システムコールを使ってプロセスを生成するため、親プロセスの状態をそのままコピーできます。一方、Windowsでは `spawn` メソッドが使われます。`spawn` は新しいプロセスを最初から初期化するため、親プロセス上で定義された状態やグローバル変数が継承されず、必要な初期化手順を踏む必要があります。\n","\n","- **`if __name__ == \"__main__\":` の重要性**: Windowsでは、コードが必ずこのブロック内で実行されるように構成する必要があります。\n","\n","- **Jupyter環境の制約**: 特にJupyter環境でのマルチプロセスはWindows上で問題を起こしやすいです。\n","\n","このノートブックでは、Windows環境を自動検出して `num_workers=0` に設定するようにしています。**パフォーマンスを最大化するには、Google Colab環境での実行を推奨します。**"]},{"cell_type":"markdown","metadata":{"id":"U2Y51_izSvyv"},"source":["## 訓練スクリプトの実行"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"vHYM5bpySvyv"},"outputs":[{"name":"stdout","output_type":"stream","text":["プロジェクトディレクトリ (/content/drive/MyDrive/NFNet_Classifier_pretrained) で main.py を実行します...\n","Google Colab 環境を検出しました。\n","設定ファイルを読み込みました: /content/drive/MyDrive/NFNet_Classifier_pretrained/configs/config_for_google_colab.yaml\n","混合精度 (16-mixed) と併用するため、torch.set_float32_matmul_precision('medium') を設定しました。\n","ログディレクトリ: /content/drive/MyDrive/NFNet_Classifier_pretrained/logs/single/efficientnet_b4\n","チェックポイントディレクトリ: /content/drive/MyDrive/NFNet_Classifier_pretrained/checkpoints/single/efficientnet_b4\n","シングルモーダルモデル (efficientnet_b4) を初期化します。\n","timmライブラリからモデル 'efficientnet_b4' を読み込みます...\n","model.safetensors: 100% 77.9M/77.9M [00:00\u003c00:00, 302MB/s]\n","モデル 'efficientnet_b4' の読み込みに成功しました。\n","モデル 'efficientnet_b4' で勾配チェックポイントを有効化しました。\n","モデル 'efficientnet_b4' の特徴次元数: 1792\n","特徴抽出器の全パラメータを初期状態で学習可能に設定しました (差分学習率モード)。\n","分類ヘッドを定義しました (Dropout1: 0.3, Dropout2: 0.2)\n","モデルタイプ 'efficientnet_b4' のステージ構造を設定します...\n","  EfficientNetの 'blocks' モジュールから 7 個のステージ (ブロックグループ) を検出しました。\n","最終的なステージ数: 7 (入力に近い層（浅い）から出力に近い層（深い）の順に格納)\n","ステージごとのパラメータ数:\n","  Stage 0 (入力から第1層): 4,146 / 4,146 パラメータ (学習可能)\n","  Stage 1 (入力から第2層): 66,238 / 66,238 パラメータ (学習可能)\n","  Stage 2 (入力から第3層): 197,586 / 197,586 パラメータ (学習可能)\n","  Stage 3 (入力から第4層): 1,059,898 / 1,059,898 パラメータ (学習可能)\n","  Stage 4 (入力から第5層): 2,306,724 / 2,306,724 パラメータ (学習可能)\n","  Stage 5 (入力から第6層): 8,636,228 / 8,636,228 パラメータ (学習可能)\n","  Stage 6 (入力から第7層): 4,470,004 / 4,470,004 パラメータ (学習可能)\n","TensorBoardロガーを設定しました (save_dir=/content/drive/MyDrive/NFNet_Classifier_pretrained/logs/single/efficientnet_b4, name=training_logs)\n","ステージ毎差分学習率 (Differential Learning Rates) が有効です (段階的凍結解除は無効)。\n","チェックポイントから学習を再開します: /content/drive/MyDrive/NFNet_Classifier_pretrained/checkpoints/singlemodal/efficientnet_b4_trial24_val_f1-val_f1=0.7180_val_loss-val_loss=0.5636_lrh2.3e-03_lrb3.7e-04.ckpt\n","Using 16bit Automatic Mixed Precision (AMP)\n","GPU available: True (cuda), used: True\n","TPU available: False, using: 0 TPU cores\n","HPU available: False, using: 0 HPUs\n","学習を開始します...\n","2025-05-16 11:55:48.008078: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2025-05-16 11:55:48.024453: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1747396548.042761    1105 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1747396548.048218    1105 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2025-05-16 11:55:48.066032: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","Restoring states from the checkpoint path at /content/drive/MyDrive/NFNet_Classifier_pretrained/checkpoints/singlemodal/efficientnet_b4_trial24_val_f1-val_f1=0.7180_val_loss-val_loss=0.5636_lrh2.3e-03_lrb3.7e-04.ckpt\n","/usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:362: The dirpath has changed from '/content/drive/MyDrive/NFNet_Classifier_pretrained/tuning/checkpoints/single/efficientnet_b4/trial_24' to '/content/drive/MyDrive/NFNet_Classifier_pretrained/checkpoints/single/efficientnet_b4', therefore `best_model_score`, `kth_best_model_path`, `kth_value`, `last_model_path` and `best_k_models` won't be reloaded. Only `best_model_path` will be reloaded.\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","  Optimizer group: stage_0 (Depth 6), lr: 1.45e-06, params: 20\n","  Optimizer group: stage_1 (Depth 5), lr: 3.65e-06, params: 52\n","  Optimizer group: stage_2 (Depth 4), lr: 9.16e-06, params: 52\n","  Optimizer group: stage_3 (Depth 3), lr: 2.30e-05, params: 78\n","  Optimizer group: stage_4 (Depth 2), lr: 5.78e-05, params: 78\n","  Optimizer group: stage_5 (Depth 1), lr: 1.45e-04, params: 104\n","  Optimizer group: stage_6 (Depth 0), lr: 3.65e-04, params: 26\n","オプティマイザ: AdamW (weight_decay=0.06361308055294002)\n","CosineAnnealingLRスケジューラを使用します (T_max=100, eta_min=1e-06)\n","\n","  | Name       | Type                      | Params | Mode \n","-----------------------------------------------------------------\n","0 | backbone   | EfficientNet              | 17.5 M | train\n","1 | classifier | Sequential                | 492 K  | train\n","2 | ce_loss    | CrossEntropyLoss          | 0      | train\n","3 | train_f1   | MulticlassF1Score         | 0      | train\n","4 | val_f1     | MulticlassF1Score         | 0      | train\n","5 | test_f1    | MulticlassF1Score         | 0      | train\n","6 | train_acc  | MulticlassAccuracy        | 0      | train\n","7 | val_acc    | MulticlassAccuracy        | 0      | train\n","8 | test_acc   | MulticlassAccuracy        | 0      | train\n","9 | val_cm     | MulticlassConfusionMatrix | 0      | train\n","-----------------------------------------------------------------\n","18.0 M    Trainable params\n","0         Non-trainable params\n","18.0 M    Total params\n","72.164    Total estimated model params size (MB)\n","669       Modules in train mode\n","0         Modules in eval mode\n","Restored all states from the checkpoint at /content/drive/MyDrive/NFNet_Classifier_pretrained/checkpoints/singlemodal/efficientnet_b4_trial24_val_f1-val_f1=0.7180_val_loss-val_loss=0.5636_lrh2.3e-03_lrb3.7e-04.ckpt\n","Sanity Checking DataLoader 0: 100% 2/2 [00:01\u003c00:00,  1.18it/s]Epoch 26 Validation Confusion Matrix:\n","tensor([[21,  0,  4],\n","        [ 0, 33,  1],\n","        [ 8,  5,  8]], device='cuda:0')\n","Epoch 27: 100% 1688/1688 [3:58:04\u003c00:00,  8.46s/it, v_num=0, train_loss_step=0.601]\n","Validation: |          | 0/? [00:00\u003c?, ?it/s]\u001b[A\n","Validation:   0% 0/422 [00:00\u003c?, ?it/s]      \u001b[A\n","Validation DataLoader 0:   0% 0/422 [00:00\u003c?, ?it/s]\u001b[A\n","Validation DataLoader 0:   5% 20/422 [01:40\u003c33:47,  5.04s/it]\u001b[A\n","Validation DataLoader 0:   9% 40/422 [04:26\u003c42:26,  6.67s/it]\u001b[A\n","Validation DataLoader 0:  14% 60/422 [07:09\u003c43:09,  7.15s/it]\u001b[A\n","Validation DataLoader 0:  19% 80/422 [10:06\u003c43:11,  7.58s/it]\u001b[A\n","Validation DataLoader 0:  24% 100/422 [12:43\u003c40:57,  7.63s/it]\u001b[A\n","Validation DataLoader 0:  28% 120/422 [15:29\u003c38:58,  7.74s/it]\u001b[A\n","Validation DataLoader 0:  33% 140/422 [18:09\u003c36:34,  7.78s/it]\u001b[A\n","Validation DataLoader 0:  38% 160/422 [20:49\u003c34:06,  7.81s/it]\u001b[A\n","Validation DataLoader 0:  43% 180/422 [23:36\u003c31:44,  7.87s/it]\u001b[A\n","Validation DataLoader 0:  47% 200/422 [26:20\u003c29:14,  7.90s/it]\u001b[A\n","Validation DataLoader 0:  52% 220/422 [29:05\u003c26:43,  7.94s/it]\u001b[A\n","Validation DataLoader 0:  57% 240/422 [31:51\u003c24:09,  7.96s/it]\u001b[A\n","Validation DataLoader 0:  62% 260/422 [34:36\u003c21:33,  7.99s/it]\u001b[A\n","Validation DataLoader 0:  66% 280/422 [37:19\u003c18:55,  8.00s/it]\u001b[A\n","Validation DataLoader 0:  71% 300/422 [40:07\u003c16:19,  8.03s/it]\u001b[A\n","Validation DataLoader 0:  76% 320/422 [42:48\u003c13:38,  8.03s/it]\u001b[A\n","Validation DataLoader 0:  81% 340/422 [45:29\u003c10:58,  8.03s/it]\u001b[A\n","Validation DataLoader 0:  85% 360/422 [48:31\u003c08:21,  8.09s/it]\u001b[A\n","Validation DataLoader 0:  90% 380/422 [51:11\u003c05:39,  8.08s/it]\u001b[A\n","Validation DataLoader 0:  95% 400/422 [53:51\u003c02:57,  8.08s/it]\u001b[A\n","Validation DataLoader 0: 100% 420/422 [56:35\u003c00:16,  8.08s/it]\u001b[A\n","Validation DataLoader 0: 100% 422/422 [56:35\u003c00:00,  8.05s/it]\u001b[AEpoch 27 Validation Confusion Matrix:\n","tensor([[5275,    0,  345],\n","        [   0, 5269,  350],\n","        [1888, 1741, 2012]], device='cuda:0')\n","\n","Epoch 27: 100% 1688/1688 [4:54:41\u003c00:00, 10.47s/it, v_num=0, train_loss_step=0.601, val_loss=0.558, val_f1=0.714, train_loss_epoch=0.507]Metric val_f1 improved. New best score: 0.714\n","Epoch 28: 100% 1688/1688 [09:05\u003c00:00,  3.10it/s, v_num=0, train_loss_step=0.463, val_loss=0.558, val_f1=0.714, train_loss_epoch=0.507, train_f1=0.745]\n","Validation: |          | 0/? [00:00\u003c?, ?it/s]\u001b[A\n","Validation:   0% 0/422 [00:00\u003c?, ?it/s]      \u001b[A\n","Validation DataLoader 0:   0% 0/422 [00:00\u003c?, ?it/s]\u001b[A\n","Validation DataLoader 0:   5% 20/422 [00:03\u003c01:18,  5.13it/s]\u001b[A\n","Validation DataLoader 0:   9% 40/422 [00:08\u003c01:22,  4.62it/s]\u001b[A\n","Validation DataLoader 0:  14% 60/422 [00:13\u003c01:20,  4.52it/s]\u001b[A\n","Validation DataLoader 0:  19% 80/422 [00:17\u003c01:16,  4.48it/s]\u001b[A\n","Validation DataLoader 0:  24% 100/422 [00:22\u003c01:12,  4.44it/s]\u001b[A\n","Validation DataLoader 0:  28% 120/422 [00:27\u003c01:08,  4.43it/s]\u001b[A\n","Validation DataLoader 0:  33% 140/422 [00:31\u003c01:04,  4.40it/s]\u001b[A\n","Validation DataLoader 0:  38% 160/422 [00:36\u003c00:59,  4.38it/s]\u001b[A\n","Validation DataLoader 0:  43% 180/422 [00:41\u003c00:55,  4.38it/s]\u001b[A\n","Validation DataLoader 0:  47% 200/422 [00:45\u003c00:50,  4.36it/s]\u001b[A\n","Validation DataLoader 0:  52% 220/422 [00:50\u003c00:46,  4.36it/s]\u001b[A\n","Validation DataLoader 0:  57% 240/422 [00:55\u003c00:41,  4.36it/s]\u001b[A\n","Validation DataLoader 0:  62% 260/422 [00:59\u003c00:37,  4.35it/s]\u001b[A\n","Validation DataLoader 0:  66% 280/422 [01:04\u003c00:32,  4.35it/s]\u001b[A\n","Validation DataLoader 0:  71% 300/422 [01:09\u003c00:28,  4.34it/s]\u001b[A\n","Validation DataLoader 0:  76% 320/422 [01:13\u003c00:23,  4.34it/s]\u001b[A\n","Validation DataLoader 0:  81% 340/422 [01:18\u003c00:18,  4.34it/s]\u001b[A\n","Validation DataLoader 0:  85% 360/422 [01:23\u003c00:14,  4.34it/s]\u001b[A\n","Validation DataLoader 0:  90% 380/422 [01:27\u003c00:09,  4.34it/s]\u001b[A\n","Validation DataLoader 0:  95% 400/422 [01:32\u003c00:05,  4.34it/s]\u001b[A\n","Validation DataLoader 0: 100% 420/422 [01:36\u003c00:00,  4.33it/s]\u001b[A\n","Validation DataLoader 0: 100% 422/422 [01:37\u003c00:00,  4.32it/s]\u001b[AEpoch 28 Validation Confusion Matrix:\n","tensor([[5290,    0,  330],\n","        [   0, 5158,  461],\n","        [1896, 1696, 2049]], device='cuda:0')\n","\n","Epoch 29: 100% 1688/1688 [09:09\u003c00:00,  3.07it/s, v_num=0, train_loss_step=0.471, val_loss=0.561, val_f1=0.712, train_loss_epoch=0.504, train_f1=0.747]\n","Validation: |          | 0/? [00:00\u003c?, ?it/s]\u001b[A\n","Validation:   0% 0/422 [00:00\u003c?, ?it/s]      \u001b[A\n","Validation DataLoader 0:   0% 0/422 [00:00\u003c?, ?it/s]\u001b[A\n","Validation DataLoader 0:   5% 20/422 [00:03\u003c01:19,  5.04it/s]\u001b[A\n","Validation DataLoader 0:   9% 40/422 [00:08\u003c01:21,  4.67it/s]\u001b[A\n","Validation DataLoader 0:  14% 60/422 [00:13\u003c01:19,  4.53it/s]\u001b[A\n","Validation DataLoader 0:  19% 80/422 [00:17\u003c01:16,  4.45it/s]\u001b[A\n","Validation DataLoader 0:  24% 100/422 [00:22\u003c01:12,  4.43it/s]\u001b[A\n","Validation DataLoader 0:  28% 120/422 [00:27\u003c01:08,  4.43it/s]\u001b[A\n","Validation DataLoader 0:  33% 140/422 [00:31\u003c01:03,  4.42it/s]\u001b[A\n","Validation DataLoader 0:  38% 160/422 [00:36\u003c00:59,  4.40it/s]\u001b[A\n","Validation DataLoader 0:  43% 180/422 [00:41\u003c00:55,  4.38it/s]\u001b[A\n","Validation DataLoader 0:  47% 200/422 [00:45\u003c00:50,  4.38it/s]\u001b[A\n","Validation DataLoader 0:  52% 220/422 [00:50\u003c00:46,  4.38it/s]\u001b[A\n","Validation DataLoader 0:  57% 240/422 [00:55\u003c00:41,  4.36it/s]\u001b[A\n","Validation DataLoader 0:  62% 260/422 [00:59\u003c00:37,  4.35it/s]\u001b[A\n","Validation DataLoader 0:  66% 280/422 [01:04\u003c00:32,  4.36it/s]\u001b[A\n","Validation DataLoader 0:  71% 300/422 [01:08\u003c00:28,  4.35it/s]\u001b[A\n","Validation DataLoader 0:  76% 320/422 [01:13\u003c00:23,  4.35it/s]\u001b[A\n","Validation DataLoader 0:  81% 340/422 [01:18\u003c00:18,  4.34it/s]\u001b[A\n","Validation DataLoader 0:  85% 360/422 [01:22\u003c00:14,  4.34it/s]\u001b[A\n","Validation DataLoader 0:  90% 380/422 [01:27\u003c00:09,  4.34it/s]\u001b[A\n","Validation DataLoader 0:  95% 400/422 [01:32\u003c00:05,  4.34it/s]\u001b[A\n","Validation DataLoader 0: 100% 420/422 [01:36\u003c00:00,  4.34it/s]\u001b[A\n","Validation DataLoader 0: 100% 422/422 [01:37\u003c00:00,  4.34it/s]\u001b[AEpoch 29 Validation Confusion Matrix:\n","tensor([[5148,    0,  472],\n","        [   0, 5085,  534],\n","        [1815, 1619, 2207]], device='cuda:0')\n","\n","Epoch 29: 100% 1688/1688 [10:48\u003c00:00,  2.60it/s, v_num=0, train_loss_step=0.471, val_loss=0.577, val_f1=0.714, train_loss_epoch=0.502, train_f1=0.747]Metric val_f1 improved by 0.000 \u003e= min_delta = 0.0. New best score: 0.714\n","Epoch 30: 100% 1688/1688 [09:12\u003c00:00,  3.06it/s, v_num=0, train_loss_step=0.523, val_loss=0.577, val_f1=0.714, train_loss_epoch=0.502, train_f1=0.748]\n","Validation: |          | 0/? [00:00\u003c?, ?it/s]\u001b[A\n","Validation:   0% 0/422 [00:00\u003c?, ?it/s]      \u001b[A\n","Validation DataLoader 0:   0% 0/422 [00:00\u003c?, ?it/s]\u001b[A\n","Validation DataLoader 0:   5% 20/422 [00:03\u003c01:17,  5.20it/s]\u001b[A\n","Validation DataLoader 0:   9% 40/422 [00:08\u003c01:21,  4.68it/s]\u001b[A\n","Validation DataLoader 0:  14% 60/422 [00:13\u003c01:19,  4.54it/s]\u001b[A\n","Validation DataLoader 0:  19% 80/422 [00:17\u003c01:15,  4.51it/s]\u001b[A\n","Validation DataLoader 0:  24% 100/422 [00:22\u003c01:12,  4.44it/s]\u001b[A\n","Validation DataLoader 0:  28% 120/422 [00:27\u003c01:08,  4.43it/s]\u001b[A\n","Validation DataLoader 0:  33% 140/422 [00:31\u003c01:03,  4.42it/s]\u001b[A\n","Validation DataLoader 0:  38% 160/422 [00:36\u003c00:59,  4.39it/s]\u001b[A\n","Validation DataLoader 0:  43% 180/422 [00:41\u003c00:55,  4.38it/s]\u001b[A\n","Validation DataLoader 0:  47% 200/422 [00:45\u003c00:50,  4.36it/s]\u001b[A\n","Validation DataLoader 0:  52% 220/422 [00:50\u003c00:46,  4.36it/s]\u001b[A\n","Validation DataLoader 0:  57% 240/422 [00:55\u003c00:41,  4.36it/s]\u001b[A\n","Validation DataLoader 0:  62% 260/422 [00:59\u003c00:37,  4.36it/s]\u001b[A\n","Validation DataLoader 0:  66% 280/422 [01:04\u003c00:32,  4.36it/s]\u001b[A\n","Validation DataLoader 0:  71% 300/422 [01:09\u003c00:28,  4.35it/s]\u001b[A\n","Validation DataLoader 0:  76% 320/422 [01:13\u003c00:23,  4.35it/s]\u001b[A\n","Validation DataLoader 0:  81% 340/422 [01:18\u003c00:18,  4.35it/s]\u001b[A\n","Validation DataLoader 0:  85% 360/422 [01:23\u003c00:14,  4.33it/s]\u001b[A\n","Validation DataLoader 0:  90% 380/422 [01:27\u003c00:09,  4.33it/s]\u001b[A\n","Validation DataLoader 0:  95% 400/422 [01:32\u003c00:05,  4.33it/s]\u001b[A\n","Validation DataLoader 0: 100% 420/422 [01:37\u003c00:00,  4.33it/s]\u001b[A\n","Validation DataLoader 0: 100% 422/422 [01:37\u003c00:00,  4.32it/s]\u001b[AEpoch 30 Validation Confusion Matrix:\n","tensor([[5197,    0,  423],\n","        [   0, 5107,  512],\n","        [1841, 1640, 2160]], device='cuda:0')\n","\n","Epoch 31: 100% 1688/1688 [09:09\u003c00:00,  3.07it/s, v_num=0, train_loss_step=0.550, val_loss=0.574, val_f1=0.714, train_loss_epoch=0.498, train_f1=0.753]\n","Validation: |          | 0/? [00:00\u003c?, ?it/s]\u001b[A\n","Validation:   0% 0/422 [00:00\u003c?, ?it/s]      \u001b[A\n","Validation DataLoader 0:   0% 0/422 [00:00\u003c?, ?it/s]\u001b[A\n","Validation DataLoader 0:   5% 20/422 [00:03\u003c01:19,  5.06it/s]\u001b[A\n","Validation DataLoader 0:   9% 40/422 [00:08\u003c01:21,  4.66it/s]\u001b[A\n","Validation DataLoader 0:  14% 60/422 [00:13\u003c01:19,  4.55it/s]\u001b[A\n","Validation DataLoader 0:  19% 80/422 [00:17\u003c01:16,  4.48it/s]\u001b[A\n","Validation DataLoader 0:  24% 100/422 [00:22\u003c01:12,  4.47it/s]\u001b[A\n","Validation DataLoader 0:  28% 120/422 [00:27\u003c01:08,  4.43it/s]\u001b[A\n","Validation DataLoader 0:  33% 140/422 [00:31\u003c01:04,  4.41it/s]\u001b[A\n","Validation DataLoader 0:  38% 160/422 [00:36\u003c00:59,  4.40it/s]\u001b[A\n","Validation DataLoader 0:  43% 180/422 [00:41\u003c00:55,  4.39it/s]\u001b[A\n","Validation DataLoader 0:  47% 200/422 [00:45\u003c00:50,  4.38it/s]\u001b[A\n","Validation DataLoader 0:  52% 220/422 [00:50\u003c00:46,  4.38it/s]\u001b[A\n","Validation DataLoader 0:  57% 240/422 [00:54\u003c00:41,  4.37it/s]\u001b[A\n","Validation DataLoader 0:  62% 260/422 [00:59\u003c00:37,  4.37it/s]\u001b[A\n","Validation DataLoader 0:  66% 280/422 [01:04\u003c00:32,  4.37it/s]\u001b[A\n","Validation DataLoader 0:  71% 300/422 [01:08\u003c00:28,  4.35it/s]\u001b[A\n","Validation DataLoader 0:  76% 320/422 [01:13\u003c00:23,  4.36it/s]\u001b[A\n","Validation DataLoader 0:  81% 340/422 [01:18\u003c00:18,  4.34it/s]\u001b[A\n","Validation DataLoader 0:  85% 360/422 [01:22\u003c00:14,  4.34it/s]\u001b[A\n","Validation DataLoader 0:  90% 380/422 [01:27\u003c00:09,  4.34it/s]\u001b[A\n","Validation DataLoader 0:  95% 400/422 [01:32\u003c00:05,  4.34it/s]\u001b[A\n","Validation DataLoader 0: 100% 420/422 [01:36\u003c00:00,  4.34it/s]\u001b[A\n","Validation DataLoader 0: 100% 422/422 [01:37\u003c00:00,  4.33it/s]\u001b[AEpoch 31 Validation Confusion Matrix:\n","tensor([[5187,    0,  433],\n","        [   0, 5098,  521],\n","        [1832, 1637, 2172]], device='cuda:0')\n","\n","Epoch 32: 100% 1688/1688 [09:09\u003c00:00,  3.07it/s, v_num=0, train_loss_step=0.398, val_loss=0.576, val_f1=0.714, train_loss_epoch=0.497, train_f1=0.752]\n","Validation: |          | 0/? [00:00\u003c?, ?it/s]\u001b[A\n","Validation:   0% 0/422 [00:00\u003c?, ?it/s]      \u001b[A\n","Validation DataLoader 0:   0% 0/422 [00:00\u003c?, ?it/s]\u001b[A\n","Validation DataLoader 0:   5% 20/422 [00:03\u003c01:18,  5.14it/s]\u001b[A\n","Validation DataLoader 0:   9% 40/422 [00:08\u003c01:20,  4.75it/s]\u001b[A\n","Validation DataLoader 0:  14% 60/422 [00:13\u003c01:19,  4.53it/s]\u001b[A\n","Validation DataLoader 0:  19% 80/422 [00:17\u003c01:16,  4.49it/s]\u001b[A\n","Validation DataLoader 0:  24% 100/422 [00:22\u003c01:12,  4.47it/s]\u001b[A\n","Validation DataLoader 0:  28% 120/422 [00:27\u003c01:08,  4.43it/s]\u001b[A\n","Validation DataLoader 0:  33% 140/422 [00:31\u003c01:03,  4.42it/s]\u001b[A\n","Validation DataLoader 0:  38% 160/422 [00:36\u003c00:59,  4.40it/s]\u001b[A\n","Validation DataLoader 0:  43% 180/422 [00:40\u003c00:54,  4.41it/s]\u001b[A\n","Validation DataLoader 0:  47% 200/422 [00:45\u003c00:50,  4.40it/s]\u001b[A\n","Validation DataLoader 0:  52% 220/422 [00:50\u003c00:45,  4.40it/s]\u001b[A\n","Validation DataLoader 0:  57% 240/422 [00:54\u003c00:41,  4.40it/s]\u001b[A\n","Validation DataLoader 0:  62% 260/422 [00:59\u003c00:36,  4.39it/s]\u001b[A\n","Validation DataLoader 0:  66% 280/422 [01:04\u003c00:32,  4.37it/s]\u001b[A\n","Validation DataLoader 0:  71% 300/422 [01:08\u003c00:27,  4.37it/s]\u001b[A\n","Validation DataLoader 0:  76% 320/422 [01:13\u003c00:23,  4.37it/s]\u001b[A\n","Validation DataLoader 0:  81% 340/422 [01:18\u003c00:18,  4.36it/s]\u001b[A\n","Validation DataLoader 0:  85% 360/422 [01:22\u003c00:14,  4.36it/s]\u001b[A\n","Validation DataLoader 0:  90% 380/422 [01:27\u003c00:09,  4.35it/s]\u001b[A\n","Validation DataLoader 0:  95% 400/422 [01:31\u003c00:05,  4.36it/s]\u001b[A\n","Validation DataLoader 0: 100% 420/422 [01:36\u003c00:00,  4.36it/s]\u001b[A\n","Validation DataLoader 0: 100% 422/422 [01:37\u003c00:00,  4.34it/s]\u001b[AEpoch 32 Validation Confusion Matrix:\n","tensor([[5120,    0,  500],\n","        [   0, 5065,  554],\n","        [1798, 1627, 2216]], device='cuda:0')\n","\n","Epoch 33: 100% 1688/1688 [09:06\u003c00:00,  3.09it/s, v_num=0, train_loss_step=0.489, val_loss=0.578, val_f1=0.712, train_loss_epoch=0.495, train_f1=0.754]\n","Validation: |          | 0/? [00:00\u003c?, ?it/s]\u001b[A\n","Validation:   0% 0/422 [00:00\u003c?, ?it/s]      \u001b[A\n","Validation DataLoader 0:   0% 0/422 [00:00\u003c?, ?it/s]\u001b[A\n","Validation DataLoader 0:   5% 20/422 [00:03\u003c01:16,  5.24it/s]\u001b[A\n","Validation DataLoader 0:   9% 40/422 [00:08\u003c01:19,  4.79it/s]\u001b[A\n","Validation DataLoader 0:  14% 60/422 [00:13\u003c01:18,  4.58it/s]\u001b[A\n","Validation DataLoader 0:  19% 80/422 [00:17\u003c01:15,  4.50it/s]\u001b[A\n","Validation DataLoader 0:  24% 100/422 [00:22\u003c01:12,  4.45it/s]\u001b[A\n","Validation DataLoader 0:  28% 120/422 [00:27\u003c01:08,  4.43it/s]\u001b[A\n","Validation DataLoader 0:  33% 140/422 [00:31\u003c01:03,  4.43it/s]\u001b[A\n","Validation DataLoader 0:  38% 160/422 [00:36\u003c00:59,  4.40it/s]\u001b[A\n","Validation DataLoader 0:  43% 180/422 [00:40\u003c00:54,  4.41it/s]\u001b[A\n","Validation DataLoader 0:  47% 200/422 [00:45\u003c00:50,  4.41it/s]\u001b[A\n","Validation DataLoader 0:  52% 220/422 [00:50\u003c00:45,  4.40it/s]\u001b[A\n","Validation DataLoader 0:  57% 240/422 [00:54\u003c00:41,  4.40it/s]\u001b[A\n","Validation DataLoader 0:  62% 260/422 [00:59\u003c00:36,  4.38it/s]\u001b[A\n","Validation DataLoader 0:  66% 280/422 [01:03\u003c00:32,  4.38it/s]\u001b[A\n","Validation DataLoader 0:  71% 300/422 [01:08\u003c00:27,  4.37it/s]\u001b[A\n","Validation DataLoader 0:  76% 320/422 [01:13\u003c00:23,  4.36it/s]\u001b[A\n","Validation DataLoader 0:  81% 340/422 [01:17\u003c00:18,  4.37it/s]\u001b[A\n","Validation DataLoader 0:  85% 360/422 [01:22\u003c00:14,  4.36it/s]\u001b[A\n","Validation DataLoader 0:  90% 380/422 [01:27\u003c00:09,  4.35it/s]\u001b[A\n","Validation DataLoader 0:  95% 400/422 [01:31\u003c00:05,  4.35it/s]\u001b[A\n","Validation DataLoader 0: 100% 420/422 [01:36\u003c00:00,  4.34it/s]\u001b[A\n","Validation DataLoader 0: 100% 422/422 [01:37\u003c00:00,  4.35it/s]\u001b[AEpoch 33 Validation Confusion Matrix:\n","tensor([[5176,    0,  444],\n","        [   0, 5099,  520],\n","        [1830, 1639, 2172]], device='cuda:0')\n","\n","Epoch 34: 100% 1688/1688 [09:12\u003c00:00,  3.06it/s, v_num=0, train_loss_step=0.466, val_loss=0.582, val_f1=0.713, train_loss_epoch=0.493, train_f1=0.755]\n","Validation: |          | 0/? [00:00\u003c?, ?it/s]\u001b[A\n","Validation:   0% 0/422 [00:00\u003c?, ?it/s]      \u001b[A\n","Validation DataLoader 0:   0% 0/422 [00:00\u003c?, ?it/s]\u001b[A\n","Validation DataLoader 0:   5% 20/422 [00:03\u003c01:18,  5.09it/s]\u001b[A\n","Validation DataLoader 0:   9% 40/422 [00:08\u003c01:22,  4.63it/s]\u001b[A\n","Validation DataLoader 0:  14% 60/422 [00:13\u003c01:19,  4.56it/s]\u001b[A\n","Validation DataLoader 0:  19% 80/422 [00:17\u003c01:16,  4.45it/s]\u001b[A\n","Validation DataLoader 0:  24% 100/422 [00:22\u003c01:12,  4.43it/s]\u001b[A\n","Validation DataLoader 0:  28% 120/422 [00:27\u003c01:08,  4.42it/s]\u001b[A\n","Validation DataLoader 0:  33% 140/422 [00:31\u003c01:04,  4.39it/s]\u001b[A\n","Validation DataLoader 0:  38% 160/422 [00:36\u003c00:59,  4.38it/s]\u001b[A\n","Validation DataLoader 0:  43% 180/422 [00:41\u003c00:55,  4.37it/s]\u001b[A\n","Validation DataLoader 0:  47% 200/422 [00:45\u003c00:50,  4.37it/s]\u001b[A\n","Validation DataLoader 0:  52% 220/422 [00:50\u003c00:46,  4.37it/s]\u001b[A\n","Validation DataLoader 0:  57% 240/422 [00:55\u003c00:41,  4.35it/s]\u001b[A\n","Validation DataLoader 0:  62% 260/422 [00:59\u003c00:37,  4.36it/s]\u001b[A\n","Validation DataLoader 0:  66% 280/422 [01:04\u003c00:32,  4.35it/s]\u001b[A\n","Validation DataLoader 0:  71% 300/422 [01:08\u003c00:28,  4.35it/s]\u001b[A\n","Validation DataLoader 0:  76% 320/422 [01:13\u003c00:23,  4.36it/s]\u001b[A\n","Validation DataLoader 0:  81% 340/422 [01:18\u003c00:18,  4.36it/s]\u001b[A\n","Validation DataLoader 0:  85% 360/422 [01:22\u003c00:14,  4.35it/s]\u001b[A\n","Validation DataLoader 0:  90% 380/422 [01:27\u003c00:09,  4.35it/s]\u001b[A\n","Validation DataLoader 0:  95% 400/422 [01:32\u003c00:05,  4.34it/s]\u001b[A\n","Validation DataLoader 0: 100% 420/422 [01:36\u003c00:00,  4.34it/s]\u001b[A\n","Validation DataLoader 0: 100% 422/422 [01:37\u003c00:00,  4.34it/s]\u001b[AEpoch 34 Validation Confusion Matrix:\n","tensor([[5179,    0,  441],\n","        [   0, 5159,  460],\n","        [1834, 1682, 2125]], device='cuda:0')\n","\n","Epoch 35: 100% 1688/1688 [09:09\u003c00:00,  3.07it/s, v_num=0, train_loss_step=0.422, val_loss=0.582, val_f1=0.713, train_loss_epoch=0.490, train_f1=0.756]\n","Validation: |          | 0/? [00:00\u003c?, ?it/s]\u001b[A\n","Validation:   0% 0/422 [00:00\u003c?, ?it/s]      \u001b[A\n","Validation DataLoader 0:   0% 0/422 [00:00\u003c?, ?it/s]\u001b[A\n","Validation DataLoader 0:   5% 20/422 [00:04\u003c01:20,  4.97it/s]\u001b[A\n","Validation DataLoader 0:   9% 40/422 [00:08\u003c01:22,  4.62it/s]\u001b[A\n","Validation DataLoader 0:  14% 60/422 [00:13\u003c01:20,  4.49it/s]\u001b[A\n","Validation DataLoader 0:  19% 80/422 [00:18\u003c01:17,  4.44it/s]\u001b[A\n","Validation DataLoader 0:  24% 100/422 [00:22\u003c01:13,  4.41it/s]\u001b[A\n","Validation DataLoader 0:  28% 120/422 [00:27\u003c01:08,  4.38it/s]\u001b[A\n","Validation DataLoader 0:  33% 140/422 [00:31\u003c01:04,  4.38it/s]\u001b[A\n","Validation DataLoader 0:  38% 160/422 [00:36\u003c00:59,  4.38it/s]\u001b[A\n","Validation DataLoader 0:  43% 180/422 [00:41\u003c00:55,  4.35it/s]\u001b[A\n","Validation DataLoader 0:  47% 200/422 [00:45\u003c00:50,  4.36it/s]\u001b[A\n","Validation DataLoader 0:  52% 220/422 [00:50\u003c00:46,  4.35it/s]\u001b[A\n","Validation DataLoader 0:  57% 240/422 [00:55\u003c00:41,  4.35it/s]\u001b[A\n","Validation DataLoader 0:  62% 260/422 [00:59\u003c00:37,  4.36it/s]\u001b[A\n","Validation DataLoader 0:  66% 280/422 [01:04\u003c00:32,  4.34it/s]\u001b[A\n","Validation DataLoader 0:  71% 300/422 [01:09\u003c00:28,  4.34it/s]\u001b[A\n","Validation DataLoader 0:  76% 320/422 [01:13\u003c00:23,  4.35it/s]\u001b[A\n","Validation DataLoader 0:  81% 340/422 [01:18\u003c00:18,  4.34it/s]\u001b[A\n","Validation DataLoader 0:  85% 360/422 [01:22\u003c00:14,  4.34it/s]\u001b[A\n","Validation DataLoader 0:  90% 380/422 [01:27\u003c00:09,  4.33it/s]\u001b[A\n","Validation DataLoader 0:  95% 400/422 [01:32\u003c00:05,  4.33it/s]\u001b[A\n","Validation DataLoader 0: 100% 420/422 [01:36\u003c00:00,  4.33it/s]\u001b[A\n","Validation DataLoader 0: 100% 422/422 [01:37\u003c00:00,  4.33it/s]\u001b[AEpoch 35 Validation Confusion Matrix:\n","tensor([[5105,    0,  515],\n","        [   0, 5157,  462],\n","        [1807, 1682, 2152]], device='cuda:0')\n","\n","Epoch 36: 100% 1688/1688 [09:10\u003c00:00,  3.06it/s, v_num=0, train_loss_step=0.518, val_loss=0.580, val_f1=0.711, train_loss_epoch=0.488, train_f1=0.758]\n","Validation: |          | 0/? [00:00\u003c?, ?it/s]\u001b[A\n","Validation:   0% 0/422 [00:00\u003c?, ?it/s]      \u001b[A\n","Validation DataLoader 0:   0% 0/422 [00:00\u003c?, ?it/s]\u001b[A\n","Validation DataLoader 0:   5% 20/422 [00:03\u003c01:17,  5.21it/s]\u001b[A\n","Validation DataLoader 0:   9% 40/422 [00:08\u003c01:22,  4.62it/s]\u001b[A\n","Validation DataLoader 0:  14% 60/422 [00:13\u003c01:20,  4.52it/s]\u001b[A\n","Validation DataLoader 0:  19% 80/422 [00:17\u003c01:16,  4.48it/s]\u001b[A\n","Validation DataLoader 0:  24% 100/422 [00:22\u003c01:12,  4.42it/s]\u001b[A\n","Validation DataLoader 0:  28% 120/422 [00:27\u003c01:08,  4.43it/s]\u001b[A\n","Validation DataLoader 0:  33% 140/422 [00:31\u003c01:04,  4.40it/s]\u001b[A\n","Validation DataLoader 0:  38% 160/422 [00:36\u003c00:59,  4.38it/s]\u001b[A\n","Validation DataLoader 0:  43% 180/422 [00:41\u003c00:55,  4.37it/s]\u001b[A\n","Validation DataLoader 0:  47% 200/422 [00:45\u003c00:50,  4.35it/s]\u001b[A\n","Validation DataLoader 0:  52% 220/422 [00:50\u003c00:46,  4.36it/s]\u001b[A\n","Validation DataLoader 0:  57% 240/422 [00:55\u003c00:41,  4.36it/s]\u001b[A\n","Validation DataLoader 0:  62% 260/422 [00:59\u003c00:37,  4.36it/s]\u001b[A\n","Validation DataLoader 0:  66% 280/422 [01:04\u003c00:32,  4.35it/s]\u001b[A\n","Validation DataLoader 0:  71% 300/422 [01:09\u003c00:28,  4.34it/s]\u001b[A\n","Validation DataLoader 0:  76% 320/422 [01:13\u003c00:23,  4.34it/s]\u001b[A\n","Validation DataLoader 0:  81% 340/422 [01:18\u003c00:18,  4.34it/s]\u001b[A\n","Validation DataLoader 0:  85% 360/422 [01:23\u003c00:14,  4.33it/s]\u001b[A\n","Validation DataLoader 0:  90% 380/422 [01:27\u003c00:09,  4.33it/s]\u001b[A\n","Validation DataLoader 0:  95% 400/422 [01:32\u003c00:05,  4.33it/s]\u001b[A\n","Validation DataLoader 0: 100% 420/422 [01:37\u003c00:00,  4.33it/s]\u001b[A\n","Validation DataLoader 0: 100% 422/422 [01:37\u003c00:00,  4.31it/s]\u001b[AEpoch 36 Validation Confusion Matrix:\n","tensor([[5162,    0,  458],\n","        [   0, 5179,  440],\n","        [1824, 1715, 2102]], device='cuda:0')\n","\n","Epoch 37: 100% 1688/1688 [09:12\u003c00:00,  3.06it/s, v_num=0, train_loss_step=0.495, val_loss=0.583, val_f1=0.711, train_loss_epoch=0.487, train_f1=0.759]\n","Validation: |          | 0/? [00:00\u003c?, ?it/s]\u001b[A\n","Validation:   0% 0/422 [00:00\u003c?, ?it/s]      \u001b[A\n","Validation DataLoader 0:   0% 0/422 [00:00\u003c?, ?it/s]\u001b[A\n","Validation DataLoader 0:   5% 20/422 [00:03\u003c01:18,  5.10it/s]\u001b[A\n","Validation DataLoader 0:   9% 40/422 [00:08\u003c01:21,  4.67it/s]\u001b[A\n","Validation DataLoader 0:  14% 60/422 [00:13\u003c01:20,  4.52it/s]\u001b[A\n","Validation DataLoader 0:  19% 80/422 [00:17\u003c01:16,  4.49it/s]\u001b[A\n","Validation DataLoader 0:  24% 100/422 [00:22\u003c01:12,  4.42it/s]\u001b[A\n","Validation DataLoader 0:  28% 120/422 [00:27\u003c01:08,  4.38it/s]\u001b[A\n","Validation DataLoader 0:  33% 140/422 [00:32\u003c01:04,  4.37it/s]\u001b[A\n","Validation DataLoader 0:  38% 160/422 [00:36\u003c01:00,  4.36it/s]\u001b[A\n","Validation DataLoader 0:  43% 180/422 [00:41\u003c00:55,  4.35it/s]\u001b[A\n","Validation DataLoader 0:  47% 200/422 [00:45\u003c00:50,  4.35it/s]\u001b[A\n","Validation DataLoader 0:  52% 220/422 [00:50\u003c00:46,  4.34it/s]\u001b[A\n","Validation DataLoader 0:  57% 240/422 [00:55\u003c00:41,  4.34it/s]\u001b[A\n","Validation DataLoader 0:  62% 260/422 [01:00\u003c00:37,  4.33it/s]\u001b[A\n","Validation DataLoader 0:  66% 280/422 [01:04\u003c00:32,  4.32it/s]\u001b[A\n","Validation DataLoader 0:  71% 300/422 [01:09\u003c00:28,  4.32it/s]\u001b[A\n","Validation DataLoader 0:  76% 320/422 [01:14\u003c00:23,  4.32it/s]\u001b[A\n","Validation DataLoader 0:  81% 340/422 [01:18\u003c00:18,  4.32it/s]\u001b[A\n","Validation DataLoader 0:  85% 360/422 [01:23\u003c00:14,  4.32it/s]\u001b[A\n","Validation DataLoader 0:  90% 380/422 [01:27\u003c00:09,  4.32it/s]\u001b[A\n","Validation DataLoader 0:  95% 400/422 [01:32\u003c00:05,  4.32it/s]\u001b[A\n","Validation DataLoader 0: 100% 420/422 [01:37\u003c00:00,  4.33it/s]\u001b[A\n","Validation DataLoader 0: 100% 422/422 [01:37\u003c00:00,  4.31it/s]\u001b[AEpoch 37 Validation Confusion Matrix:\n","tensor([[5106,    0,  514],\n","        [   0, 5118,  501],\n","        [1798, 1661, 2182]], device='cuda:0')\n","\n","Epoch 38: 100% 1688/1688 [09:09\u003c00:00,  3.07it/s, v_num=0, train_loss_step=0.438, val_loss=0.587, val_f1=0.712, train_loss_epoch=0.487, train_f1=0.760]\n","Validation: |          | 0/? [00:00\u003c?, ?it/s]\u001b[A\n","Validation:   0% 0/422 [00:00\u003c?, ?it/s]      \u001b[A\n","Validation DataLoader 0:   0% 0/422 [00:00\u003c?, ?it/s]\u001b[A\n","Validation DataLoader 0:   5% 20/422 [00:03\u003c01:18,  5.14it/s]\u001b[A\n","Validation DataLoader 0:   9% 40/422 [00:08\u003c01:21,  4.66it/s]\u001b[A\n","Validation DataLoader 0:  14% 60/422 [00:13\u003c01:19,  4.55it/s]\u001b[A\n","Validation DataLoader 0:  19% 80/422 [00:17\u003c01:16,  4.49it/s]\u001b[A\n","Validation DataLoader 0:  24% 100/422 [00:22\u003c01:12,  4.42it/s]\u001b[A\n","Validation DataLoader 0:  28% 120/422 [00:27\u003c01:08,  4.40it/s]\u001b[A\n","Validation DataLoader 0:  33% 140/422 [00:31\u003c01:04,  4.39it/s]\u001b[A\n","Validation DataLoader 0:  38% 160/422 [00:36\u003c01:00,  4.35it/s]\u001b[A\n","Validation DataLoader 0:  43% 180/422 [00:41\u003c00:55,  4.34it/s]\u001b[A\n","Validation DataLoader 0:  47% 200/422 [00:46\u003c00:51,  4.33it/s]\u001b[A\n","Validation DataLoader 0:  52% 220/422 [00:50\u003c00:46,  4.34it/s]\u001b[A\n","Validation DataLoader 0:  57% 240/422 [00:55\u003c00:41,  4.35it/s]\u001b[A\n","Validation DataLoader 0:  62% 260/422 [00:59\u003c00:37,  4.34it/s]\u001b[A\n","Validation DataLoader 0:  66% 280/422 [01:04\u003c00:32,  4.34it/s]\u001b[A\n","Validation DataLoader 0:  71% 300/422 [01:09\u003c00:28,  4.33it/s]\u001b[A\n","Validation DataLoader 0:  76% 320/422 [01:13\u003c00:23,  4.33it/s]\u001b[A\n","Validation DataLoader 0:  81% 340/422 [01:18\u003c00:18,  4.33it/s]\u001b[A\n","Validation DataLoader 0:  85% 360/422 [01:23\u003c00:14,  4.33it/s]\u001b[A\n","Validation DataLoader 0:  90% 380/422 [01:27\u003c00:09,  4.34it/s]\u001b[A\n","Validation DataLoader 0:  95% 400/422 [01:32\u003c00:05,  4.34it/s]\u001b[A\n","Validation DataLoader 0: 100% 420/422 [01:36\u003c00:00,  4.33it/s]\u001b[A\n","Validation DataLoader 0: 100% 422/422 [01:37\u003c00:00,  4.32it/s]\u001b[AEpoch 38 Validation Confusion Matrix:\n","tensor([[5139,    0,  481],\n","        [   0, 5026,  593],\n","        [1822, 1613, 2206]], device='cuda:0')\n","\n","Epoch 39: 100% 1688/1688 [09:09\u003c00:00,  3.07it/s, v_num=0, train_loss_step=0.509, val_loss=0.588, val_f1=0.711, train_loss_epoch=0.487, train_f1=0.759]\n","Validation: |          | 0/? [00:00\u003c?, ?it/s]\u001b[A\n","Validation:   0% 0/422 [00:00\u003c?, ?it/s]      \u001b[A\n","Validation DataLoader 0:   0% 0/422 [00:00\u003c?, ?it/s]\u001b[A\n","Validation DataLoader 0:   5% 20/422 [00:04\u003c01:22,  4.88it/s]\u001b[A\n","Validation DataLoader 0:   9% 40/422 [00:08\u003c01:23,  4.60it/s]\u001b[A\n","Validation DataLoader 0:  14% 60/422 [00:13\u003c01:19,  4.54it/s]\u001b[A\n","Validation DataLoader 0:  19% 80/422 [00:17\u003c01:16,  4.46it/s]\u001b[A\n","Validation DataLoader 0:  24% 100/422 [00:22\u003c01:12,  4.45it/s]\u001b[A\n","Validation DataLoader 0:  28% 120/422 [00:27\u003c01:08,  4.41it/s]\u001b[A\n","Validation DataLoader 0:  33% 140/422 [00:31\u003c01:04,  4.38it/s]\u001b[A\n","Validation DataLoader 0:  38% 160/422 [00:36\u003c00:59,  4.38it/s]\u001b[A\n","Validation DataLoader 0:  43% 180/422 [00:41\u003c00:55,  4.36it/s]\u001b[A\n","Validation DataLoader 0:  47% 200/422 [00:45\u003c00:50,  4.36it/s]\u001b[A\n","Validation DataLoader 0:  52% 220/422 [00:50\u003c00:46,  4.37it/s]\u001b[A\n","Validation DataLoader 0:  57% 240/422 [00:55\u003c00:41,  4.36it/s]\u001b[A\n","Validation DataLoader 0:  62% 260/422 [00:59\u003c00:37,  4.36it/s]\u001b[A\n","Validation DataLoader 0:  66% 280/422 [01:04\u003c00:32,  4.35it/s]\u001b[A\n","Validation DataLoader 0:  71% 300/422 [01:09\u003c00:28,  4.34it/s]\u001b[A\n","Validation DataLoader 0:  76% 320/422 [01:13\u003c00:23,  4.34it/s]\u001b[A\n","Validation DataLoader 0:  81% 340/422 [01:18\u003c00:18,  4.34it/s]\u001b[A\n","Validation DataLoader 0:  85% 360/422 [01:22\u003c00:14,  4.34it/s]\u001b[A\n","Validation DataLoader 0:  90% 380/422 [01:27\u003c00:09,  4.35it/s]\u001b[A\n","Validation DataLoader 0:  95% 400/422 [01:32\u003c00:05,  4.34it/s]\u001b[A\n","Validation DataLoader 0: 100% 420/422 [01:36\u003c00:00,  4.34it/s]\u001b[A\n","Validation DataLoader 0: 100% 422/422 [01:37\u003c00:00,  4.34it/s]\u001b[AEpoch 39 Validation Confusion Matrix:\n","tensor([[5107,    0,  513],\n","        [   0, 5055,  564],\n","        [1803, 1626, 2212]], device='cuda:0')\n","\n","Epoch 39: 100% 1688/1688 [10:47\u003c00:00,  2.61it/s, v_num=0, train_loss_step=0.509, val_loss=0.589, val_f1=0.711, train_loss_epoch=0.485, train_f1=0.759]Monitored metric val_f1 did not improve in the last 10 records. Best score: 0.714. Signaling Trainer to stop.\n","Epoch 39: 100% 1688/1688 [10:49\u003c00:00,  2.60it/s, v_num=0, train_loss_step=0.509, val_loss=0.589, val_f1=0.711, train_loss_epoch=0.485, train_f1=0.759]\n","学習が完了しました。\n","テストを開始します...\n","最良モデルをロードしてテスト: /content/drive/MyDrive/NFNet_Classifier_pretrained/checkpoints/single/efficientnet_b4/epoch=00029-val_loss=0.5772-val_f1=0.7140.ckpt\n","Restoring states from the checkpoint path at /content/drive/MyDrive/NFNet_Classifier_pretrained/checkpoints/single/efficientnet_b4/epoch=00029-val_loss=0.5772-val_f1=0.7140.ckpt\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","Loaded model weights from the checkpoint at /content/drive/MyDrive/NFNet_Classifier_pretrained/checkpoints/single/efficientnet_b4/epoch=00029-val_loss=0.5772-val_f1=0.7140.ckpt\n","Testing DataLoader 0: 100% 528/528 [1:03:24\u003c00:00,  7.21s/it]\n","┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│\u001b[36m \u001b[0m\u001b[36m     test_acc_epoch      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.736824631690979    \u001b[0m\u001b[35m \u001b[0m│\n","│\u001b[36m \u001b[0m\u001b[36m      test_f1_epoch      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7131251692771912    \u001b[0m\u001b[35m \u001b[0m│\n","│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5757339000701904    \u001b[0m\u001b[35m \u001b[0m│\n","└───────────────────────────┴───────────────────────────┘\n","テストが完了しました。\n"]}],"source":["# main.py を実行して訓練を開始\n","# main.py は内部で環境を判断し、適切な設定ファイルを読み込みます\n","print(f\"プロジェクトディレクトリ ({project_dir}) で main.py を実行します...\")\n","# !python main.py コマンドを実行\n","# ノートブック環境からPythonスクリプトを実行する場合、カレントディレクトリに注意\n","# 上のセルで os.chdir を使ってプロジェクトディレクトリに移動済みのはず\n","! python main.py"]},{"cell_type":"markdown","metadata":{"id":"IGz9qIjYha8t"},"source":["## チェックポイントからの学習再開\n","\n","学習を途中から再開する場合、このセクションを使用します。resume_training.pyを実行し、指定したチェックポイントから学習を再開します。\n","事前にconfigs/resume_settings.yamlファイルを編集して、使用するチェックポイントと学習設定を指定してください。"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":81876,"status":"ok","timestamp":1747394002512,"user":{"displayName":"土倉恵一郎","userId":"13053641895557367934"},"user_tz":-540},"id":"cGGMqr0Fha8t","outputId":"7f1a62f1-0ba1-47ac-ab0e-4b0ffad4c18b"},"outputs":[{"name":"stdout","output_type":"stream","text":["プロジェクトディレクトリ (/content/drive/MyDrive/NFNet_Classifier_pretrained) でresume_training.pyを実行します...\n","--- 再開設定ファイル内容 ---\n","# 訓練再開用の設定ファイル\n","\n","# チェックポイントの設定\n","checkpoint:\n","  # 再開するチェックポイントファイルのパス\n","  # 例: \"model_epoch_00011_val_loss_0.9229_val_f1_0.6907.ckpt\"\n","  # 例: \"last.ckpt\"\n","  path: \"model_epoch_00011_val_loss_0.9229_val_f1_0.6907.ckpt\" # ★ 再開したいチェックポイントに合わせて変更してください\n","\n","# 訓練設定\n","training:\n","  # 最大エポック数（この設定ファイルでの訓練セッションで実行するエポック数）\n","  # 注意: これはチェックポイントのエポック数に追加されるのではなく、\n","  #       Trainerのmax_epochsとして設定されます。\n","  #       実質的に「この再開セッションで何エポック進めるか」を指定します。\n","  #       例えば、45エポックで中断し、合計100エポックまで学習したい場合、\n","  #       max_epochs: 100 と設定します。\n","  max_epochs: 40 # ★ 目標とする総エポック数、またはこのセッションでの追加エポック数に合わせて調整\n","  \n","  # チェックポイント保存頻度\n","  save_every_n_epochs: 1\n","  \n","  # トレーナー設定 (main.pyと同様の設定を反映)\n","  precision: '16-mixed' # 混合精度計算 (16-mixed, 32-true, bf16-mixedなど)\n","  accumulate_grad_batches: 2 # 勾配累積ステップ数\n","  log_every_n_steps: 50 # ログ記録頻度 (ステップごと)\n","  early_stopping_patience: 10 # val_f1 がこのエポック数改善しなかったら停止\n","  \n","  # バッチサイズ (元の設定を上書きする場合のみ指定)\n","  # batch_size: 64\n","\n","# ハードウェア設定\n","hardware:\n","  # GPU使用設定\n","  force_gpu: true # GPUを強制的に使用する場合はtrue\n","  force_cpu: false # CPUを強制的に使用する場合はtrue\n","  \n","  # データローダー設定\n","  num_workers: 4 # Google Colab環境では4以上推奨、Windows環境では0を推奨\n","  pin_memory: true # GPUメモリへのピン留め (GPU使用時は通常true)\n","  persistent_workers: true # ワーカープロセスを保持 (num_workers \u003e 0の場合のみ有効)\n","  prefetch_factor: 2 # データプリフェッチ係数 (num_workers \u003e 0の場合のみ有効)\n","\n","# モデル設定の上書き (オプション)\n","# model:\n","#   drop_path_rate: 0.25 # ドロップパス率を変更する場合\n","#   use_agc: false # AGCを無効にする場合\n","\n","# オプティマイザ設定の上書き (オプション)\n","# optimizer:\n","#   lr_head: 0.0002 # ヘッド部分の学習率を変更する場合\n","#   lr_backbone: 0.00003 # バックボーン部分の学習率を変更する場合\n","#   weight_decay: 0.03 # 重み減衰を変更する場合\n","----------------------\n","Google Colab環境を検出しました。\n","再開用設定ファイルを読み込み中: /content/drive/MyDrive/NFNet_Classifier_pretrained/configs/resume_settings.yaml\n","元の設定ファイル 'config_for_google_colab.yaml' を読み込みました。\n","チェックポイントからエポック情報を抽出中: /content/drive/MyDrive/NFNet_Classifier_pretrained/checkpoints/model_epoch_00011_val_loss_0.9229_val_f1_0.6907.ckpt\n","チェックポイントのエポック数: 11\n","チェックポイントからモデルを読み込み中: /content/drive/MyDrive/NFNet_Classifier_pretrained/checkpoints/model_epoch_00011_val_loss_0.9229_val_f1_0.6907.ckpt\n","model.safetensors: 100% 286M/286M [00:11\u003c00:00, 24.0MB/s]\n","timmライブラリからNFNet-F0モデルを読み込みました (drop_path_rate=0.20889964802961225)\n","NFNetモデル構造:\n","  モデル主要部: stem\n","  モデル主要部: stages\n","  モデル主要部: final_conv\n","  モデル主要部: final_act\n","  モデル主要部: head\n","NFNet特徴抽出器出力サイズ: torch.Size([1, 3072, 12, 12]), 平坦化後次元: 442368\n","  'stages'モジュールを検出しました\n","  ステージ0を検出しました\n","  ステージ1を検出しました\n","  ステージ2を検出しました\n","  ステージ3を検出しました\n","NFNet構造確認: 4個のステージを検出しました\n","ステージ0: 444,545 パラメータ\n","ステージ1: 2,301,442 パラメータ\n","ステージ2: 38,991,366 パラメータ\n","ステージ3: 21,856,515 パラメータ\n","エラー: モデルのロードに失敗しました: Error(s) in loading state_dict for StockClassifier:\n","\tUnexpected key(s) in state_dict: \"reasoning_head.0.weight\", \"reasoning_head.0.bias\", \"reasoning_head.3.weight\", \"reasoning_head.3.bias\", \"reasoning_head.6.weight\", \"reasoning_head.6.bias\". \n","\tsize mismatch for classifier.0.weight: copying a param with shape torch.Size([256, 371715]) from checkpoint, the shape in current model is torch.Size([256, 442368]).\n"]}],"source":["# # resume_training.py を実行して学習を再開\n","# print(f\"プロジェクトディレクトリ ({project_dir}) でresume_training.pyを実行します...\")\n","# # まず現在の設定ファイルの内容を確認\n","# import os\n","\n","# # resume_settings.yamlの内容を確認\n","# resume_settings_path = os.path.join(project_dir, 'configs', 'resume_settings.yaml')\n","# try:\n","#     with open(resume_settings_path, 'r', encoding='utf-8') as f:\n","#         print(\"--- 再開設定ファイル内容 ---\")\n","#         print(f.read())\n","#         print(\"----------------------\")\n","# except FileNotFoundError:\n","#     print(f\"エラー: 再開設定ファイル {resume_settings_path} が見つかりません。プロジェクト構成を確認してください。\")\n","# except IOError as e:\n","#     print(f\"再開設定ファイルの読み込み中にエラーが発生しました: {e}\")\n","\n","# # シンプルな呼び出しに留める（引数はresume_settings.yamlから読み込まれる）\n","# ! python src/resume_training.py"]},{"cell_type":"markdown","metadata":{"id":"SwW6xwbpSvyv"},"source":["## TensorBoardによる訓練の可視化"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"vAfpBU9cSvyv"},"outputs":[{"name":"stdout","output_type":"stream","text":["TensorBoard ログディレクトリ: /content/drive/MyDrive/NFNet_Classifier_pretrained/logs/stock_classifier\n"]},{"data":{"application/javascript":["\n","        (async () =\u003e {\n","            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n","            url.searchParams.set('tensorboardColab', 'true');\n","            const iframe = document.createElement('iframe');\n","            iframe.src = url;\n","            iframe.setAttribute('width', '100%');\n","            iframe.setAttribute('height', '800');\n","            iframe.setAttribute('frameborder', 0);\n","            document.body.appendChild(iframe);\n","        })();\n","    "],"text/plain":["\u003cIPython.core.display.Javascript object\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["import os\n","# config_utils.py が configs ディレクトリにあることを確認\n","try:\n","    # src と configs が sys.path にあるため、直接インポート\n","    from config_utils import load_config # config読み込み用ユーティリティ\n","except ImportError:\n","    print(\"エラー: config_utils が見つかりません。Pythonパスを確認してください。\")\n","    # 必要であればパスを再度追加\n","    configs_dir = os.path.join(project_dir, 'configs')\n","    if configs_dir not in sys.path:\n","        sys.path.insert(0, configs_dir)\n","        print(f\"'{configs_dir}' をPythonパスに追加しました。\")\n","        try:\n","            from config_utils import load_config\n","        except ImportError as ie:\n","             print(f\"再試行しましたが、config_utils のインポートに失敗しました: {ie}\")\n","             # ここで処理を中断するか、デフォルトパスを使うなどの代替策を検討\n","             raise ie # エラーを再発生させる\n","\n","# 設定ファイルを再度読み込み、ログディレクトリを取得\n","try:\n","    # config_path が前のセルで定義されていることを確認\n","    if 'config_path' not in globals():\n","        raise NameError(\"'config_path' is not defined. Please run the cell defining it.\")\n","    config = load_config(config_path)\n","    # log_dir_tb = config.get(\"logs_dir\", os.path.join(project_dir, \"logs\")) # 設定ファイルから取得する代わりに、期待されるパスを直接構築\n","    experiment_name = \"stock_classifier\" # main.pyでの設定と合わせる\n","    # 正しいログディレクトリのベースパスを構築\n","    correct_log_base_dir = os.path.join(project_dir, \"logs\")\n","    tensorboard_logdir = os.path.join(correct_log_base_dir, experiment_name) # 常に logs/stock_classifier を指すように修正\n","\n","    # Colab用のTensorBoard拡張を読み込む\n","    if IN_COLAB:\n","        %load_ext tensorboard\n","        print(f\"TensorBoard ログディレクトリ: {tensorboard_logdir}\")\n","        # パスにスペースが含まれる可能性を考慮して引用符で囲む\n","        %tensorboard --logdir=\"{tensorboard_logdir}\"\n","    else:\n","        print(\"ローカル環境です。TensorBoardを手動で起動してください:\")\n","        # Windowsの場合、パスをダブルクォーテーションで囲むのが一般的\n","        print(f\"tensorboard --logdir=\\\"{tensorboard_logdir}\\\"\")\n","except FileNotFoundError:\n","    print(f\"エラー: 設定ファイル {config_path} が見つかりません。\")\n","except NameError as e:\n","    print(f\"エラー: 必要な変数(config_pathなど)が定義されていません - {e}\")\n","except KeyError as e:\n","    print(f\"エラー: 設定ファイルに必要なキー ('logs_dir'など) がありません - {e}\")\n","# 広範な例外捕捉は避ける\n","except Exception as e: # より具体的な例外を捕捉することが望ましい\n","    print(f\"TensorBoardの準備中に予期せぬエラーが発生しました: {e}\")\n","    import traceback\n","    traceback.print_exc()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"8bd4_7xBx3-D"},"outputs":[{"name":"stdout","output_type":"stream","text":["find_best_checkpoint 関数が定義されました。\n"]}],"source":["# 新しいセルに追加するコード\n","import os\n","import re\n","import sys\n","import yaml # yaml をインポート\n","\n","# config_utils が見つからない場合に備えてパスを追加\n","# project_dir は ID '9f53d608' のセルで定義されている想定\n","try:\n","    from configs.config_utils import load_config, get_project_root\n","except ImportError:\n","    print(\"config_utils が見つかりません。パスを確認・追加します。\")\n","    configs_dir_util = os.path.join(project_dir, 'configs')\n","    if configs_dir_util not in sys.path:\n","        sys.path.insert(0, configs_dir_util)\n","        print(f\"'{configs_dir_util}' をPythonパスに追加しました。\")\n","        try:\n","            from configs.config_utils import load_config, get_project_root\n","        except ImportError as ie_util:\n","            print(f\"再試行しましたが、config_utils のインポートに失敗しました: {ie_util}\")\n","            raise ie_util # エラーを再発生\n","\n","# find_best_checkpoint 関数の定義 (evaluate.py/visualize.py と同じもの)\n","def find_best_checkpoint(config, metric=\"f1\"):\n","    \"\"\"\n","    指定されたメトリックに基づいて最適なチェックポイントファイルを見つける。\n","    新しいディレクトリ構造とファイル名形式に対応。\n","\n","    Args:\n","        config (dict): 設定辞書。'model_mode', 'model_architecture_name' を含む。\n","        metric (str): 最適化するメトリック ('f1' または 'loss')。\n","\n","    Returns:\n","        str or None: 最適なチェックポイントファイルのパス。見つからない場合はNone。\n","    \"\"\"\n","    # project_root は get_project_root() で取得するか、ノートブックの project_dir を使う\n","    # ここでは get_project_root() を使う\n","    try:\n","        project_root = get_project_root()\n","    except Exception as e_proj_root:\n","         print(f\"get_project_root() でエラー: {e_proj_root}. ノートブックの 'project_dir' を使用します。\")\n","         # project_dir がグローバルスコープにあることを期待\n","         if 'project_dir' not in globals():\n","              print(\"エラー: 'project_dir' 変数が定義されていません。\")\n","              return None\n","         project_root = project_dir\n","\n","    model_mode = config.get(\"model_mode\", \"single\")\n","    model_architecture_name = config.get(\"model_architecture_name\", \"default_model\")\n","    # 新しいチェックポイントディレクトリパスを構築\n","    # config から checkpoint_dir を取得し、その下に model_mode/model_architecture_name を追加\n","    base_checkpoint_dir = config.get(\"checkpoint_dir\", os.path.join(project_root, \"checkpoints\"))\n","    checkpoint_dir = os.path.join(base_checkpoint_dir, model_mode, model_architecture_name)\n","\n","    print(f\"チェックポイントディレクトリを検索中: {checkpoint_dir}\")\n","\n","    if not os.path.isdir(checkpoint_dir):\n","        print(f\"エラー: チェックポイントディレクトリが見つかりません: {checkpoint_dir}\")\n","        # 設定ファイルで指定された base_checkpoint_dir も確認\n","        if base_checkpoint_dir != checkpoint_dir and os.path.isdir(base_checkpoint_dir):\n","             print(f\"警告: サブディレクトリ '{model_mode}/{model_architecture_name}' はありませんが、ベースディレクトリ '{base_checkpoint_dir}' は存在します。\")\n","             # ベースディレクトリ内も検索するかどうか？ -\u003e ここではしない\n","        return None\n","\n","    # 新しいファイル名形式 'epoch={epoch:05d}-val_loss={val_loss:.4f}-val_f1={val_f1:.4f}.ckpt'\n","    # metric に応じた正規表現パターン\n","    if metric == \"f1\":\n","        # val_f1 を抽出するパターン\n","        pattern = re.compile(r'epoch=(\\d+)-val_loss=([\\d.]+)-val_f1=([\\d.]+)\\.ckpt')\n","        metric_index = 2 # F1スコアは3番目のキャプチャグループ (0-based index)\n","        best_metric_val = -1.0 # F1スコアは高いほど良い\n","        compare_func = lambda current, best: current \u003e best\n","    elif metric == \"loss\":\n","        # val_loss を抽出するパターン\n","        pattern = re.compile(r'epoch=(\\d+)-val_loss=([\\d.]+)-val_f1=([\\d.]+)\\.ckpt')\n","        metric_index = 1 # 損失は2番目のキャプチャグループ\n","        best_metric_val = float('inf') # 損失は低いほど良い\n","        compare_func = lambda current, best: current \u003c best\n","    else:\n","        print(f\"エラー: 未知のメトリック '{metric}'。'f1' または 'loss' を使用してください。\")\n","        return None\n","\n","    best_checkpoint_path = None\n","    found_checkpoints = []\n","    last_ckpt_path = None # last.ckpt のパスを初期化\n","\n","    try:\n","        for filename in os.listdir(checkpoint_dir):\n","            match = pattern.match(filename)\n","            if match:\n","                found_checkpoints.append(filename)\n","                try:\n","                    # 指定されたメトリックの値を抽出\n","                    current_metric_val = float(match.group(metric_index + 1)) # グループインデックスは1から始まるため+1\n","                    print(f\"  チェックポイント '{filename}' の {metric}: {current_metric_val}\")\n","                    # 最良のメトリック値を更新\n","                    if compare_func(current_metric_val, best_metric_val):\n","                        best_metric_val = current_metric_val\n","                        best_checkpoint_path = os.path.join(checkpoint_dir, filename)\n","                except (ValueError, IndexError) as e:\n","                    print(f\"  警告: ファイル '{filename}' のメトリック値の解析中にエラー: {e}\")\n","                    continue\n","            # 'last.ckpt' も候補として保持 (最良が見つからない場合に使用)\n","            elif filename == \"last.ckpt\":\n","                 last_ckpt_path = os.path.join(checkpoint_dir, filename)\n","\n","    except OSError as e:\n","        print(f\"エラー: チェックポイントディレクトリの読み取り中にエラーが発生しました: {e}\")\n","        return None\n","\n","    if best_checkpoint_path:\n","        print(f\"最適な {metric} ({best_metric_val:.4f}) を持つチェックポイントが見つかりました: {best_checkpoint_path}\")\n","        return best_checkpoint_path\n","    elif last_ckpt_path and os.path.exists(last_ckpt_path): # last_ckpt_path が None でないことを確認\n","         print(f\"警告: 最適な {metric} を持つチェックポイントが見つかりませんでした。'last.ckpt' を使用します: {last_ckpt_path}\")\n","         return last_ckpt_path\n","    else:\n","        print(f\"警告: 有効なチェックポイントファイルがディレクトリ '{checkpoint_dir}' に見つかりませんでした。\")\n","        # last.ckpt も見つからなかった場合、古い形式のチェックポイントをベースディレクトリで探す試み（オプション）\n","        print(f\"念のため、ベースディレクトリ '{base_checkpoint_dir}' で古い形式の 'last.ckpt' を探します...\")\n","        old_last_ckpt = os.path.join(base_checkpoint_dir, 'last.ckpt')\n","        if os.path.exists(old_last_ckpt):\n","             print(f\"警告: ベースディレクトリで古い形式の 'last.ckpt' を見つけました。これを使用します: {old_last_ckpt}\")\n","             return old_last_ckpt\n","        else:\n","             print(f\"警告: ベースディレクトリにも 'last.ckpt' が見つかりませんでした。\")\n","             return None\n","\n","print(\"find_best_checkpoint 関数が定義されました。\")"]},{"cell_type":"markdown","metadata":{"id":"rSWUFAx_Svyv"},"source":["## 学習済みモデルのテストと評価"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"XujtP7ooSvyw"},"outputs":[{"name":"stdout","output_type":"stream","text":["チェックポイントディレクトリ: /content/drive/MyDrive/NFNet_Classifier_pretrained/checkpoints\n","見つかったチェックポイント候補: ['model_epoch_00003_val_loss_0.8376_val_f1_0.6373.ckpt', 'model_epoch_00004_val_loss_0.8325_val_f1_0.6246.ckpt', 'model_epoch_00004_val_loss_0.9122_val_f1_0.5962.ckpt', 'model_epoch_00005_val_loss_0.9121_val_f1_0.5860.ckpt', 'model_epoch_00008_val_loss_0.9033_val_f1_0.6560.ckpt', 'model_epoch_00011_val_loss_0.9229_val_f1_0.6907.ckpt', 'model_epoch_00011_val_loss_0.9878_val_f1_0.6678.ckpt', 'model_epoch_00051_val_loss_0.7755_val_f1_0.6688.ckpt', 'model_epoch_00061_val_loss_0.7953_val_f1_0.6718.ckpt']\n","  警告: ファイル 'model_epoch_00003_val_loss_0.8376_val_f1_0.6373.ckpt' の解析中にエラーが発生しました: could not convert string to float: '0.6373.'\n","  警告: ファイル 'model_epoch_00004_val_loss_0.8325_val_f1_0.6246.ckpt' の解析中にエラーが発生しました: could not convert string to float: '0.6246.'\n","  警告: ファイル 'model_epoch_00004_val_loss_0.9122_val_f1_0.5962.ckpt' の解析中にエラーが発生しました: could not convert string to float: '0.5962.'\n","  警告: ファイル 'model_epoch_00005_val_loss_0.9121_val_f1_0.5860.ckpt' の解析中にエラーが発生しました: could not convert string to float: '0.5860.'\n","  警告: ファイル 'model_epoch_00008_val_loss_0.9033_val_f1_0.6560.ckpt' の解析中にエラーが発生しました: could not convert string to float: '0.6560.'\n","  警告: ファイル 'model_epoch_00011_val_loss_0.9229_val_f1_0.6907.ckpt' の解析中にエラーが発生しました: could not convert string to float: '0.6907.'\n","  警告: ファイル 'model_epoch_00011_val_loss_0.9878_val_f1_0.6678.ckpt' の解析中にエラーが発生しました: could not convert string to float: '0.6678.'\n","  警告: ファイル 'model_epoch_00051_val_loss_0.7755_val_f1_0.6688.ckpt' の解析中にエラーが発生しました: could not convert string to float: '0.6688.'\n","  警告: ファイル 'model_epoch_00061_val_loss_0.7953_val_f1_0.6718.ckpt' の解析中にエラーが発生しました: could not convert string to float: '0.6718.'\n","F1スコアを含む有効なチェックポイントが見つかりませんでした。\n","最良のF1チェックポイントが見つかりません。最新のチェックポイントを使用します: /content/drive/MyDrive/NFNet_Classifier_pretrained/checkpoints/last.ckpt\n","評価に使用するチェックポイント: /content/drive/MyDrive/NFNet_Classifier_pretrained/checkpoints/last.ckpt\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n","Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n","You are not authenticated with the Hugging Face Hub in this notebook.\n","If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c10bacbd15fc455d8850a297635c3540","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/286M [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["timmライブラリからNFNet-F0モデルを読み込みました (drop_path_rate=0.20889964802961225)\n","NFNetモデル構造:\n","  モデル主要部: stem\n","  モデル主要部: stages\n","  モデル主要部: final_conv\n","  モデル主要部: final_act\n","  モデル主要部: head\n","NFNet特徴抽出器出力サイズ: torch.Size([1, 3072, 12, 12]), 平坦化後次元: 442368\n","  'stages'モジュールを検出しました\n","  ステージ0を検出しました\n","  ステージ1を検出しました\n","  ステージ2を検出しました\n","  ステージ3を検出しました\n","NFNet構造確認: 4個のステージを検出しました\n","ステージ0: 444,545 パラメータ\n","ステージ1: 2,301,442 パラメータ\n","ステージ2: 38,991,366 パラメータ\n","ステージ3: 21,856,515 パラメータ\n","モデルのロード中にエラーが発生しました: Error(s) in loading state_dict for StockClassifier:\n","\tsize mismatch for classifier.0.weight: copying a param with shape torch.Size([128, 150531]) from checkpoint, the shape in current model is torch.Size([256, 442368]).\n","\tsize mismatch for classifier.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n","テスト準備または実行中に予期せぬエラーが発生しました: Error(s) in loading state_dict for StockClassifier:\n","\tsize mismatch for classifier.0.weight: copying a param with shape torch.Size([128, 150531]) from checkpoint, the shape in current model is torch.Size([256, 442368]).\n","\tsize mismatch for classifier.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n"]},{"name":"stderr","output_type":"stream","text":["Traceback (most recent call last):\n","  File \"\u003cipython-input-9-978849090189\u003e\", line 116, in \u003ccell line: 0\u003e\n","    raise model_load_err\n","  File \"\u003cipython-input-9-978849090189\u003e\", line 109, in \u003ccell line: 0\u003e\n","    model = StockClassifier.load_from_checkpoint(best_checkpoint_path, config=config, strict=False)\n","            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/lightning/pytorch/utilities/model_helpers.py\", line 125, in wrapper\n","    return self.method(cls, *args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/module.py\", line 1581, in load_from_checkpoint\n","    loaded = _load_from_checkpoint(\n","             ^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/saving.py\", line 91, in _load_from_checkpoint\n","    model = _load_state(cls, checkpoint, strict=strict, **kwargs)\n","            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/saving.py\", line 187, in _load_state\n","    keys = obj.load_state_dict(checkpoint[\"state_dict\"], strict=strict)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 2581, in load_state_dict\n","    raise RuntimeError(\n","RuntimeError: Error(s) in loading state_dict for StockClassifier:\n","\tsize mismatch for classifier.0.weight: copying a param with shape torch.Size([128, 150531]) from checkpoint, the shape in current model is torch.Size([256, 442368]).\n","\tsize mismatch for classifier.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n"]}],"source":["# 学習後、最良のモデルを使って評価を実行するには\n","# すでにテストは訓練時に実行されているはずですが、個別に実行したい場合は以下を利用\n","\n","import os\n","import sys\n","import torch\n","import lightning.pytorch as pl # lightning に変更\n","import re\n","\n","# モジュールパスの確認 (必要であれば)\n","# 最初のセルで追加済みのはずだが、念のため確認・追加\n","project_root_dir_test = os.path.abspath(os.path.join(os.getcwd())) # main.pyと同じ階層を想定\n","src_dir_test = os.path.join(project_root_dir_test, 'src')\n","configs_dir_test = os.path.join(project_root_dir_test, 'configs')\n","\n","if src_dir_test not in sys.path:\n","    sys.path.insert(0, src_dir_test)\n","if configs_dir_test not in sys.path:\n","     sys.path.insert(0, configs_dir_test)\n","\n","try:\n","    # src と configs が sys.path にあるため、直接インポート\n","    from model import StockClassifier\n","    from datamodule import StockDataModule\n","    from config_utils import load_config\n","except ImportError as e:\n","    print(f\"必要なモジュールのインポートに失敗しました: {e}\")\n","    print(\"モジュールパスを確認してください。sys.path:\", sys.path)\n","    # インポート失敗時は処理を中断\n","    raise e\n","\n","try:\n","    # 設定ファイルの読み込み（訓練時と同じものを使用）\n","    # config_path は前のセルで定義されている想定\n","    if 'config_path' not in globals():\n","        # config_path が未定義の場合、環境に応じて再設定\n","        if IN_COLAB:\n","            config_filename_test = 'config_for_google_colab.yaml'\n","        else:\n","            config_filename_test = 'config.yaml'\n","        config_path = os.path.join(project_root_dir_test, 'configs', config_filename_test)\n","        print(f\"警告: 'config_path' が未定義でした。'{config_path}' を使用します。\")\n","\n","    config = load_config(config_path)\n","\n","    # 最良モデルのチェックポイントパスを取得\n","    # configからcheckpoint_dirを取得、なければデフォルトパス\n","    checkpoint_dir_path = config.get(\"checkpoint_dir\", os.path.join(project_root_dir_test, \"checkpoints\"))\n","    print(f\"チェックポイントディレクトリ: {checkpoint_dir_path}\")\n","\n","    # ModelCheckpointで設定したファイル名パターンに基づいて探す\n","    # val_f1 が最高のモデルを探す (mode='max')\n","    # ファイル名形式: 'model_epoch_{epoch:05d}_val_loss_{val_loss:.4f}_val_f1_{val_f1:.4f}.ckpt'\n","    checkpoints = []\n","    if os.path.isdir(checkpoint_dir_path):\n","        checkpoints = [f for f in os.listdir(checkpoint_dir_path) if f.startswith(\"model_epoch_\") and \"val_f1_\" in f and f.endswith(\".ckpt\")]\n","    else:\n","        print(f\"エラー: チェックポイントディレクトリが見つかりません: {checkpoint_dir_path}\")\n","\n","    best_checkpoint_path = None\n","    best_f1 = -1.0\n","\n","    if checkpoints:\n","        print(f\"見つかったチェックポイント候補: {checkpoints}\")\n","        # 正規表現を使用してファイル名からval_f1の値を抽出\n","        f1_pattern = re.compile(r'val_f1_([0-9.]+)')\n","        for fname in checkpoints:\n","            try:\n","                # 正規表現でF1スコアを抽出 (例: model_epoch_00011_val_loss_0.9229_val_f1_0.6907.ckpt → 0.6907)\n","                f1_match = f1_pattern.search(fname)\n","                if f1_match:\n","                    current_f1 = float(f1_match.group(1))\n","                    print(f\"  チェックポイント '{fname}' の F1スコア: {current_f1}\")\n","                    if current_f1 \u003e best_f1:\n","                        best_f1 = current_f1\n","                        best_checkpoint_path = os.path.join(checkpoint_dir_path, fname)\n","                else:\n","                    print(f\"  警告: ファイル '{fname}' からF1スコアを抽出できませんでした (パターンに一致しない)\")\n","            except (ValueError, AttributeError) as parse_err:\n","                print(f\"  警告: ファイル '{fname}' の解析中にエラーが発生しました: {parse_err}\")\n","                continue # 次のファイルへ\n","        if best_checkpoint_path:\n","             print(f\"最高のF1スコア ({best_f1:.4f}) を持つチェックポイントが見つかりました: {best_checkpoint_path}\")\n","        else:\n","             print(\"F1スコアを含む有効なチェックポイントが見つかりませんでした。\")\n","\n","    # 最良が見つからない場合は last.ckpt を試す\n","    if best_checkpoint_path is None:\n","        last_ckpt = os.path.join(checkpoint_dir_path, 'last.ckpt')\n","        if os.path.exists(last_ckpt):\n","            best_checkpoint_path = last_ckpt\n","            print(f\"最良のF1チェックポイントが見つかりません。最新のチェックポイントを使用します: {best_checkpoint_path}\")\n","        else:\n","             # last.ckpt も見つからない場合\n","             print(f\"エラー: 評価に使用できるチェックポイント ('model_e...val_f1...' または 'last.ckpt') がディレクトリ '{checkpoint_dir_path}' に見つかりません。\")\n","             # エラーにするか、Noneのまま進むかは要件次第\n","             # ここでは None のまま進み、後続のifで処理する\n","\n","    if best_checkpoint_path:\n","        print(f\"評価に使用するチェックポイント: {best_checkpoint_path}\")\n","        # データモジュールの準備（テスト用）\n","        data_module = StockDataModule(config)\n","        # data_module.setup(\"test\") # testメソッド内で自動的に呼ばれる\n","\n","        # モデルのロード\n","        # configを渡して、チェックポイント保存時と異なる可能性のある設定に対応\n","        # strict=False は、モデル構造が変わっていない限り、一部の不一致を許容する\n","        try:\n","            model = StockClassifier.load_from_checkpoint(best_checkpoint_path, config=config, strict=False)\n","            print(\"モデルのロードに成功しました。\")\n","        except FileNotFoundError as model_load_err:\n","            print(f\"エラー: チェックポイントファイルが見つかりません: {model_load_err}\")\n","            raise model_load_err\n","        except Exception as model_load_err: # より具体的な例外捕捉が望ましい\n","            print(f\"モデルのロード中にエラーが発生しました: {model_load_err}\")\n","            raise model_load_err\n","\n","        # テスト用トレーナーの設定\n","        # accelerator と devices を config や環境に合わせて設定\n","        accelerator_setting = \"auto\"\n","        devices_setting = \"auto\"\n","        if config.get(\"force_gpu\", False) and torch.cuda.is_available():\n","            accelerator_setting = \"gpu\"\n","            devices_setting = 1 # テストは通常1デバイス\n","        elif config.get(\"force_cpu\", False):\n","            accelerator_setting = \"cpu\"\n","            devices_setting = 1\n","\n","        tester = pl.Trainer(\n","            accelerator=accelerator_setting,\n","            devices=devices_setting,\n","            logger=False, # テスト結果はログ不要\n","            precision=config.get('precision', '32-true') # 訓練時と同じ精度を使用\n","        )\n","\n","        # テストの実行\n","        print(\"\\nテストを再実行します...\")\n","        try:\n","            test_results = tester.test(model, datamodule=data_module)\n","            print(\"\\nテスト結果:\")\n","            print(test_results)\n","        except Exception as test_err: # より具体的な例外捕捉が望ましい\n","             print(f\"テストの実行中にエラーが発生しました: {test_err}\")\n","             import traceback\n","             traceback.print_exc()\n","\n","    else:\n","        # best_checkpoint_path が None の場合（チェックポイントが見つからなかった場合）\n","        print(\"テストを実行できませんでした。有効なチェックポイントが見つかりません。\")\n","\n","# FileNotFoundError は設定ファイル読み込み時に発生する可能性\n","# KeyError は config 辞書に必要なキーがない場合に発生する可能性\n","# NameError は config_path など、前のセルで定義されるべき変数が未定義の場合\n","# ImportError はモジュールインポート失敗時\n","except (FileNotFoundError, KeyError, NameError, ImportError) as e:\n","    print(f\"エラーが発生しました: {e}\")\n","# 広範な例外捕捉は避ける\n","except Exception as e: # より具体的な例外を捕捉することが望ましい\n","    print(f\"テスト準備または実行中に予期せぬエラーが発生しました: {e}\")\n","    import traceback\n","    traceback.print_exc()"]},{"cell_type":"markdown","metadata":{"id":"9bhU03pqSvyw"},"source":["## モデル予測の可視化（オプション）"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":169477,"status":"error","timestamp":1747394216157,"user":{"displayName":"土倉恵一郎","userId":"13053641895557367934"},"user_tz":-540},"id":"N_YxUYiImK13","outputId":"6939f521-f16b-43e9-9587-a74f27d07f6f"},"outputs":[{"name":"stdout","output_type":"stream","text":["data_module または model が未定義です。再定義/再ロードを試みます...\n","DataModuleをセットアップしました (stage='test')。\n","前のセルで特定されたチェックポイントを使用します: /content/drive/MyDrive/NFNet_Classifier_pretrained/checkpoints/last.ckpt\n","timmライブラリからNFNet-F0モデルを読み込みました (drop_path_rate=0.20889964802961225)\n","NFNetモデル構造:\n","  モデル主要部: stem\n","  モデル主要部: stages\n","  モデル主要部: final_conv\n","  モデル主要部: final_act\n","  モデル主要部: head\n","NFNet特徴抽出器出力サイズ: torch.Size([1, 3072, 12, 12]), 平坦化後次元: 442368\n","  'stages'モジュールを検出しました\n","  ステージ0を検出しました\n","  ステージ1を検出しました\n","  ステージ2を検出しました\n","  ステージ3を検出しました\n","NFNet構造確認: 4個のステージを検出しました\n","ステージ0: 444,545 パラメータ\n","ステージ1: 2,301,442 パラメータ\n","ステージ2: 38,991,366 パラメータ\n","ステージ3: 21,856,515 パラメータ\n","可視化のための再定義/再ロード中に予期せぬエラーが発生しました: Error(s) in loading state_dict for StockClassifier:\n","\tsize mismatch for classifier.0.weight: copying a param with shape torch.Size([128, 150531]) from checkpoint, the shape in current model is torch.Size([256, 442368]).\n","\tsize mismatch for classifier.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n"]},{"name":"stderr","output_type":"stream","text":["Traceback (most recent call last):\n","  File \"\u003cipython-input-11-e6de35d6fa14\u003e\", line 51, in \u003ccell line: 0\u003e\n","    model = StockClassifier.load_from_checkpoint(best_checkpoint_path, config=config, strict=False)\n","            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/lightning/pytorch/utilities/model_helpers.py\", line 125, in wrapper\n","    return self.method(cls, *args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/module.py\", line 1581, in load_from_checkpoint\n","    loaded = _load_from_checkpoint(\n","             ^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/saving.py\", line 91, in _load_from_checkpoint\n","    model = _load_state(cls, checkpoint, strict=strict, **kwargs)\n","            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/saving.py\", line 187, in _load_state\n","    keys = obj.load_state_dict(checkpoint[\"state_dict\"], strict=strict)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 2581, in load_state_dict\n","    raise RuntimeError(\n","RuntimeError: Error(s) in loading state_dict for StockClassifier:\n","\tsize mismatch for classifier.0.weight: copying a param with shape torch.Size([128, 150531]) from checkpoint, the shape in current model is torch.Size([256, 442368]).\n","\tsize mismatch for classifier.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n"]},{"ename":"RuntimeError","evalue":"Error(s) in loading state_dict for StockClassifier:\n\tsize mismatch for classifier.0.weight: copying a param with shape torch.Size([128, 150531]) from checkpoint, the shape in current model is torch.Size([256, 442368]).\n\tsize mismatch for classifier.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-11-e6de35d6fa14\u003e\u001b[0m in \u001b[0;36m\u003ccell line: 0\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mtraceback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_exc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;31m# エラー発生時は以降のセルが実行できないため、再発生させる\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 111\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data_module と model は既に定義済みです。\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m\u003cipython-input-11-e6de35d6fa14\u003e\u001b[0m in \u001b[0;36m\u003ccell line: 0\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'best_checkpoint_path'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbest_checkpoint_path\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_checkpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m              \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"前のセルで特定されたチェックポイントを使用します: {best_checkpoint_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 51\u001b[0;31m              \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStockClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_checkpoint_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m              \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"モデルを {best_checkpoint_path} からロードしました。\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/utilities/model_helpers.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m                     \u001b[0;34m\" Please call it on the class type and make sure the return value is used.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m                 )\n\u001b[0;32m--\u003e 125\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/module.py\u001b[0m in \u001b[0;36mload_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m   1579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1580\u001b[0m         \"\"\"\n\u001b[0;32m-\u003e 1581\u001b[0;31m         loaded = _load_from_checkpoint(\n\u001b[0m\u001b[1;32m   1582\u001b[0m             \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1583\u001b[0m             \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/saving.py\u001b[0m in \u001b[0;36m_load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLightningModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 91\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"state_dict\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/saving.py\u001b[0m in \u001b[0;36m_load_state\u001b[0;34m(cls, checkpoint, strict, **cls_kwargs_new)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# load the state_dict on the model automatically\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 187\u001b[0;31m     \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"state_dict\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m\u003e\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 2581\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   2582\u001b[0m                 \"Error(s) in loading state_dict for {}:\\n\\t{}\".format(\n\u001b[1;32m   2583\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\\t\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for StockClassifier:\n\tsize mismatch for classifier.0.weight: copying a param with shape torch.Size([128, 150531]) from checkpoint, the shape in current model is torch.Size([256, 442368]).\n\tsize mismatch for classifier.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256])."]}],"source":["# 必要な変数が定義されているか確認し、なければ再定義/ロード\n","import os\n","import sys\n","import torch\n","import re\n","\n","# モジュールパスの確認 (必要であれば)\n","# 最初のセルで追加済みのはずだが、念のため確認・追加\n","project_root_dir_vis = os.path.abspath(os.path.join(os.getcwd()))\n","src_dir_vis = os.path.join(project_root_dir_vis, 'src')\n","configs_dir_vis = os.path.join(project_root_dir_vis, 'configs')\n","\n","if src_dir_vis not in sys.path:\n","    sys.path.insert(0, src_dir_vis)\n","if configs_dir_vis not in sys.path:\n","     sys.path.insert(0, configs_dir_vis)\n","\n","# グローバルスコープに変数が存在するかチェック\n","# 存在しない場合のみ再ロードを試みる\n","if 'data_module' not in globals() or 'model' not in globals():\n","    print(\"data_module または model が未定義です。再定義/再ロードを試みます...\")\n","    try:\n","        # src と configs が sys.path にあるため、直接インポート\n","        from model import StockClassifier\n","        from datamodule import StockDataModule\n","        from config_utils import load_config\n","\n","        # 設定ファイルの読み込み\n","        # config_path は前のセルで定義されている想定\n","        if 'config_path' not in globals():\n","            # config_path が未定義の場合、環境に応じて再設定\n","            if IN_COLAB:\n","                config_filename_vis = 'config_for_google_colab.yaml'\n","            else:\n","                config_filename_vis = 'config.yaml'\n","            config_path = os.path.join(project_root_dir_vis, 'configs', config_filename_vis)\n","            print(f\"警告: 'config_path' が未定義でした。'{config_path}' を使用します。\")\n","\n","        config = load_config(config_path)\n","        # データモジュールの準備\n","        data_module = StockDataModule(config)\n","        # 可視化にはテストデータを使うことが多いので 'test' を指定\n","        # setup() は dataloader() 呼び出し時に内部で実行される場合もあるが、明示的に呼ぶ\n","        data_module.setup('test')\n","        print(\"DataModuleをセットアップしました (stage='test')。\")\n","\n","        # モデルのロード（前のセルで特定した最良または最新のチェックポイントから）\n","        # best_checkpoint_path が前のセルで定義されていることを期待\n","        if 'best_checkpoint_path' in globals() and best_checkpoint_path and os.path.exists(best_checkpoint_path):\n","             print(f\"前のセルで特定されたチェックポイントを使用します: {best_checkpoint_path}\")\n","             model = StockClassifier.load_from_checkpoint(best_checkpoint_path, config=config, strict=False)\n","             print(f\"モデルを {best_checkpoint_path} からロードしました。\")\n","        else:\n","             # best_checkpoint_path が未定義または無効な場合、再度探す\n","             print(\"警告: 'best_checkpoint_path' が未定義または無効です。再度チェックポイントを探します...\")\n","             checkpoint_dir_path_vis = config.get(\"checkpoint_dir\", os.path.join(project_root_dir_vis, \"checkpoints\"))\n","             # 前のセルと同様のロジックで最良チェックポイントを探す\n","             checkpoints_vis = []\n","             if os.path.isdir(checkpoint_dir_path_vis):\n","                 checkpoints_vis = [f for f in os.listdir(checkpoint_dir_path_vis) if f.startswith(\"model_epoch_\") and \"val_f1_\" in f and f.endswith(\".ckpt\")]\n","             temp_best_path = None\n","             temp_best_f1 = -1.0\n","             if checkpoints_vis:\n","                 print(f\"見つかったチェックポイント候補: {checkpoints_vis}\")\n","                 # 正規表現を使用してファイル名からval_f1の値を抽出\n","                 f1_pattern = re.compile(r'val_f1_([0-9.]+)')\n","                 for fname in checkpoints_vis:\n","                     try:\n","                         # 正規表現でF1スコアを抽出 (例: model_epoch_00011_val_loss_0.9229_val_f1_0.6907.ckpt → 0.6907)\n","                         f1_match = f1_pattern.search(fname)\n","                         if f1_match:\n","                             current_f1 = float(f1_match.group(1))\n","                             print(f\"  チェックポイント '{fname}' の F1スコア: {current_f1}\")\n","                             if current_f1 \u003e temp_best_f1:\n","                                 temp_best_f1 = current_f1\n","                                 temp_best_path = os.path.join(checkpoint_dir_path_vis, fname)\n","                         else:\n","                             print(f\"  警告: ファイル '{fname}' からF1スコアを抽出できませんでした (パターンに一致しない)\")\n","                     except (ValueError, AttributeError) as parse_err:\n","                         print(f\"  警告: ファイル '{fname}' の解析中にエラーが発生しました: {parse_err}\")\n","                         continue # 次のファイルへ\n","             if temp_best_path:\n","                 best_checkpoint_path = temp_best_path # グローバル変数も更新\n","                 print(f\"最高のF1スコア ({temp_best_f1:.4f}) を持つチェックポイントを再検出しました: {best_checkpoint_path}\")\n","                 model = StockClassifier.load_from_checkpoint(best_checkpoint_path, config=config, strict=False)\n","                 print(f\"モデルを {best_checkpoint_path} からロードしました。\")\n","             else:\n","                 last_ckpt_vis = os.path.join(checkpoint_dir_path_vis, 'last.ckpt')\n","                 if os.path.exists(last_ckpt_vis):\n","                     best_checkpoint_path = last_ckpt_vis # グローバル変数も更新\n","                     print(f\"最良が見つからず、最新のモデルを使用します: {best_checkpoint_path}\")\n","                     model = StockClassifier.load_from_checkpoint(best_checkpoint_path, config=config, strict=False)\n","                     print(f\"モデルを {best_checkpoint_path} からロードしました。\")\n","                 else:\n","                     print(f\"エラー: ロードするモデルのチェックポイントがディレクトリ '{checkpoint_dir_path_vis}' に見つかりません。\")\n","                     raise FileNotFoundError(f\"チェックポイントが見つかりません in {checkpoint_dir_path_vis}\")\n","\n","    # ImportError はモジュールが見つからない場合\n","    # FileNotFoundError は設定ファイルやチェックポイントが見つからない場合\n","    # NameError は config_path などが未定義の場合\n","    except (ImportError, FileNotFoundError, NameError) as e:\n","        print(f\"エラーが発生しました: {e}\")\n","        # エラー発生時は以降のセルが実行できないため、再発生させる\n","        raise e\n","    # 広範な例外捕捉は避ける\n","    except Exception as e: # より具体的な例外を捕捉することが望ましい\n","        print(f\"可視化のための再定義/再ロード中に予期せぬエラーが発生しました: {e}\")\n","        import traceback\n","        traceback.print_exc()\n","        # エラー発生時は以降のセルが実行できないため、再発生させる\n","        raise e\n","else:\n","    print(\"data_module と model は既に定義済みです。\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uLBX4KDXSvyw"},"outputs":[],"source":["# テストデータから数サンプルを選び、予測結果を可視化する\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import torch\n","from torchvision import transforms\n","import random\n","import sys\n","import os\n","\n","try:\n","    # 設定ファイルからクラス名と正規化パラメータを取得\n","    # config がロードされていることを確認\n","    if 'config' not in globals():\n","        # config がなければロードを試みる\n","        print(\"警告: 'config' が未定義です。ロードを試みます...\")\n","        configs_dir_vis2 = os.path.join(project_dir, 'configs') # project_dir は最初のセルで定義済みのはず\n","        if configs_dir_vis2 not in sys.path:\n","             sys.path.insert(0, configs_dir_vis2)\n","        try:\n","            from config_utils import load_config\n","        except ImportError as ie:\n","             print(f\"config_utils のインポートに失敗しました: {ie}\")\n","             raise ie\n","        if 'config_path' not in globals():\n","             # config_path が未定義の場合、環境に応じて再設定\n","             if IN_COLAB:\n","                 config_filename_vis2 = 'config_for_google_colab.yaml'\n","             else:\n","                 config_filename_vis2 = 'config.yaml'\n","             config_path = os.path.join(project_dir, 'configs', config_filename_vis2)\n","             print(f\"警告: 'config_path' が未定義でした。'{config_path}' を使用します。\")\n","        try:\n","            config = load_config(config_path)\n","        except FileNotFoundError as fe:\n","            print(f\"設定ファイルが見つかりません: {fe}\")\n","            raise fe\n","        except yaml.YAMLError as ye:\n","            print(f\"設定ファイルの解析エラー: {ye}\")\n","            raise ye\n","\n","    # config からクラス名、平均、標準偏差を取得、なければデフォルト値\n","    class_names = config.get('class_names', ['Class 0', 'Class 1', 'Class 2'])\n","    mean = config.get('dataset_mean', [0.485, 0.456, 0.406])\n","    std = config.get('dataset_std', [0.229, 0.224, 0.225])\n","    print(f\"クラス名: {class_names}\")\n","    print(f\"データセット平均: {mean}, 標準偏差: {std}\")\n","\n","    # データローダーからランダムに1バッチ取得\n","    # data_module がロードされていることを確認\n","    if 'data_module' not in globals():\n","         raise NameError(\"data_module が定義されていません。前のセルを実行してください。\")\n","    try:\n","        test_loader = data_module.test_dataloader()\n","        images, labels = next(iter(test_loader))\n","        print(f\"テストローダーからバッチを取得しました。画像形状: {images.shape}, ラベル形状: {labels.shape}\")\n","    except StopIteration:\n","        print(\"エラー: テストデータローダーが空です。\")\n","        # データがない場合は処理を中断\n","        raise StopIteration(\"テストデータがありません\")\n","    except Exception as dl_err: # DataLoaderに関する他のエラー\n","        print(f\"データローダーからのバッチ取得中にエラー: {dl_err}\")\n","        raise dl_err\n","\n","    # モデルを評価モードに設定\n","    # model がロードされていることを確認\n","    if 'model' not in globals():\n","        raise NameError(\"model が定義されていません。前のセルを実行してください。\")\n","    model.eval()\n","    print(\"モデルを評価モードに設定しました。\")\n","\n","    # GPUが利用可能ならモデルとデータをGPUへ移動\n","    # config から force_gpu を取得、なければデフォルト False\n","    use_gpu = config.get('force_gpu', False) and torch.cuda.is_available()\n","    device = torch.device(\"cuda\" if use_gpu else \"cpu\")\n","    print(f\"使用デバイス: {device}\")\n","    try:\n","        model.to(device)\n","        images = images.to(device)\n","    except Exception as device_err:\n","        print(f\"モデルまたはデータのデバイス転送中にエラー: {device_err}\")\n","        raise device_err\n","\n","    # 予測実行\n","    print(\"予測を実行します...\")\n","    with torch.no_grad():\n","        try:\n","            # --- 修正箇所 ---\n","            # model(images) の戻り値が logits のみであると仮定して修正\n","            logits = model(images)\n","            # reasoning_soft は削除\n","            # --- 修正箇所ここまで ---\n","\n","            # 結果をCPUに戻してから計算（メモリ節約とNumPy変換のため）\n","            logits = logits.cpu()\n","            probs = torch.nn.functional.softmax(logits, dim=1)\n","            preds = torch.argmax(logits, dim=1)\n","            print(\"予測が完了しました。\")\n","        except Exception as pred_err:\n","            print(f\"モデルのフォワードパス実行中にエラー: {pred_err}\")\n","            raise pred_err # エラーを再発生させてトレースバックを表示\n","\n","    # 結果の可視化\n","    print(\"結果を可視化します...\")\n","    # 正規化解除のための変換\n","    try:\n","        inv_normalize = transforms.Normalize(\n","            mean=[-m/s for m, s in zip(mean, std)],\n","            std=[1/s for s in std]\n","        )\n","    except ZeroDivisionError:\n","        print(\"エラー: 標準偏差にゼロが含まれています。設定ファイルを確認してください。\")\n","        raise ZeroDivisionError(\"標準偏差がゼロです\")\n","\n","    # 表示する画像数を決定 (最大8枚)\n","    num_images_to_show = min(8, len(images))\n","    if num_images_to_show == 0:\n","        print(\"表示する画像がありません。\")\n","    else:\n","        # 描画領域のサイズ調整 (4列表示を想定)\n","        num_rows = (num_images_to_show + 3) // 4\n","        plt.figure(figsize=(16, 4 * num_rows)) # 横幅を少し広げる\n","\n","        # バッチの先頭から表示\n","        indices = range(num_images_to_show)\n","\n","        for i, idx in enumerate(indices):\n","            plt.subplot(num_rows, 4, i + 1)\n","            # 画像をCPUに戻し、正規化を解除して表示用に次元を並び替え\n","            img_tensor = images[idx].cpu() # 元のテンソルをCPUへ\n","            try:\n","                img = inv_normalize(img_tensor).permute(1, 2, 0).numpy()\n","            except Exception as norm_err:\n","                print(f\"画像の正規化解除または次元並び替え中にエラー: {norm_err}\")\n","                # エラーが発生した画像はスキップ\n","                plt.title(\"表示エラー\")\n","                plt.axis('off')\n","                continue\n","\n","            # 値を0-1の範囲にクリップ (正規化解除で範囲外になる可能性)\n","            img = np.clip(img, 0, 1)\n","            plt.imshow(img)\n","\n","            # ラベルと予測を取得\n","            true_label_idx = labels[idx].item()\n","            pred_label_idx = preds[idx].item()\n","\n","            # クラス名リスト外のインデックスアクセスを防ぐ\n","            true_label_name = class_names[true_label_idx] if 0 \u003c= true_label_idx \u003c len(class_names) else f\"Unknown({true_label_idx})\"\n","            pred_label_name = class_names[pred_label_idx] if 0 \u003c= pred_label_idx \u003c len(class_names) else f\"Unknown({pred_label_idx})\"\n","\n","            # タイトルに真ラベル、予測ラベル、予測確率を表示\n","            plt.title(f\"True: {true_label_name}\\nPred: {pred_label_name} (Prob: {probs[idx][pred_label_idx]:.2f})\")\n","            plt.axis('off') # 軸を非表示に\n","\n","        plt.tight_layout() # サブプロット間のスペースを調整\n","        plt.show()\n","        print(\"可視化が完了しました。\")\n","\n","# NameError は model, data_module, config_path, config が未定義の場合\n","# FileNotFoundError は設定ファイルが見つからない場合（configロード時）\n","# KeyError は config 辞書に必要なキーがない場合\n","# AttributeError はオブジェクトに必要な属性がない場合（例: model.eval()）\n","# StopIteration はデータローダーが空の場合\n","# ZeroDivisionError は標準偏差がゼロの場合\n","except (NameError, FileNotFoundError, KeyError, AttributeError, StopIteration, ZeroDivisionError) as e:\n","     print(f\"可視化に必要な変数、設定、またはデータが見つからないか、アクセスできませんでした: {e}\")\n","# 広範な例外捕捉は避ける\n","except Exception as e: # より具体的な例外を捕捉することが望ましい\n","    print(f\"予測結果の可視化中に予期せぬエラーが発生しました: {e}\")\n","    import traceback\n","    traceback.print_exc()"]},{"cell_type":"markdown","metadata":{"id":"64S2RnsBSvyw"},"source":["## 混同行列の可視化"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kOSIqLFySvyw"},"outputs":[],"source":["# テストデータセット全体での混同行列を表示\n","from sklearn.metrics import confusion_matrix, classification_report\n","import seaborn as sns\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import torch\n","import numpy as np\n","import sys\n","import os\n","\n","try:\n","    # 設定ファイルからクラス名を取得\n","    # config がロードされていることを確認\n","    if 'config' not in globals():\n","        # config がなければロードを試みる\n","        print(\"警告: 'config' が未定義です。ロードを試みます...\")\n","        configs_dir_cm = os.path.join(project_dir, 'configs') # project_dir は最初のセルで定義済みのはず\n","        if configs_dir_cm not in sys.path:\n","             sys.path.insert(0, configs_dir_cm)\n","        try:\n","            from config_utils import load_config\n","        except ImportError as ie:\n","             print(f\"config_utils のインポートに失敗しました: {ie}\")\n","             raise ie\n","        if 'config_path' not in globals():\n","             # config_path が未定義の場合、環境に応じて再設定\n","             if IN_COLAB:\n","                 config_filename_cm = 'config_for_google_colab.yaml'\n","             else:\n","                 config_filename_cm = 'config.yaml'\n","             config_path = os.path.join(project_dir, 'configs', config_filename_cm)\n","             print(f\"警告: 'config_path' が未定義でした。'{config_path}' を使用します。\")\n","        try:\n","            config = load_config(config_path)\n","        except FileNotFoundError as fe:\n","            print(f\"設定ファイルが見つかりません: {fe}\")\n","            raise fe\n","        except yaml.YAMLError as ye:\n","            print(f\"設定ファイルの解析エラー: {ye}\")\n","            raise ye\n","\n","    # config からクラス名を取得、なければデフォルト値\n","    class_names = config.get('class_names', ['Sell', 'Buy', 'Hold'])\n","    print(f\"クラス名: {class_names}\")\n","\n","    # すべてのテストデータでの予測を収集するためのリスト\n","    true_labels = []\n","    pred_labels = []\n","\n","    # モデルを評価モードに\n","    # model がロードされていることを確認\n","    if 'model' not in globals():\n","        raise NameError(\"model が定義されていません。前のセルを実行してください。\")\n","    model.eval()\n","    print(\"モデルを評価モードに設定しました。\")\n","\n","    # GPUが利用可能ならモデルをGPUへ\n","    # config から force_gpu を取得、なければデフォルト False\n","    use_gpu_cm = config.get('force_gpu', False) and torch.cuda.is_available()\n","    device_cm = torch.device(\"cuda\" if use_gpu_cm else \"cpu\")\n","    print(f\"使用デバイス: {device_cm}\")\n","    try:\n","        model.to(device_cm)\n","    except Exception as device_err_cm:\n","        print(f\"モデルのデバイス転送中にエラー: {device_err_cm}\")\n","        raise device_err_cm\n","\n","    print(\"テストデータ全体で予測を収集しています...\")\n","    # data_module がロードされていることを確認\n","    if 'data_module' not in globals():\n","        raise NameError(\"data_module が定義されていません。前のセルを実行してください。\")\n","\n","    try:\n","        test_loader_cm = data_module.test_dataloader()\n","        with torch.no_grad():\n","            for batch in test_loader_cm:\n","                images, labels = batch\n","                # データを適切なデバイスへ\n","                try:\n","                    images = images.to(device_cm)\n","                except Exception as batch_device_err:\n","                    print(f\"バッチデータのデバイス転送中にエラー: {batch_device_err}\")\n","                    # このバッチをスキップするか、エラーを発生させるか検討\n","                    continue # スキップする場合\n","\n","                # 予測実行\n","                try:\n","                    # --- 修正箇所 ---\n","                    # model(images) の戻り値が logits のみであると仮定して修正\n","                    logits = model(images) # reasoning_soft は削除\n","                    # --- 修正箇所ここまで ---\n","                    preds = torch.argmax(logits, dim=1)\n","                except Exception as batch_pred_err:\n","                    print(f\"バッチ予測中にエラー: {batch_pred_err}\")\n","                    # このバッチをスキップするか、エラーを発生させるか検討\n","                    continue # スキップする場合\n","\n","                # 結果をCPUに集める (NumPy変換のため)\n","                true_labels.extend(labels.cpu().numpy())\n","                pred_labels.extend(preds.cpu().numpy())\n","    except StopIteration:\n","         print(\"警告: テストデータローダーが空でした。混同行列は計算できません。\")\n","         # データがない場合は以降の処理をスキップ\n","         # raise StopIteration(\"テストデータがありません\") # またはここで終了\n","    except Exception as collect_err:\n","         print(f\"予測収集中にエラーが発生しました: {collect_err}\")\n","         raise collect_err\n","\n","    # 予測が収集できた場合のみ混同行列を計算・表示\n","    if true_labels and pred_labels:\n","        print(\"予測の収集が完了しました。混同行列を計算・表示します。\")\n","\n","        # 混同行列の計算\n","        try:\n","            cm = confusion_matrix(true_labels, pred_labels)\n","        except ValueError as cm_err:\n","             print(f\"混同行列の計算中にエラー: {cm_err}\")\n","             # ラベルの不一致などが考えられる\n","             raise cm_err\n","\n","        # 混同行列の可視化\n","        plt.figure(figsize=(8, 6)) # サイズを少し調整\n","        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n","                    xticklabels=class_names, yticklabels=class_names)\n","        plt.xlabel('Predicted Label') # ラベル名を修正\n","        plt.ylabel('True Label')     # ラベル名を修正\n","        plt.title('Confusion Matrix')\n","        plt.show()\n","\n","        # 詳細な分類レポートを表示\n","        print(\"\\n分類レポート:\")\n","        try:\n","            # zero_division=0 を追加して、ゼロ除算が発生した場合の警告を抑制し、値を0にする\n","            report = classification_report(true_labels, pred_labels, target_names=class_names, digits=4, zero_division=0)\n","            print(report)\n","        except ValueError as report_err:\n","             print(f\"分類レポートの生成中にエラー: {report_err}\")\n","             # ラベルの不一致などが考えられる\n","             raise report_err\n","    else:\n","        print(\"予測データが収集されなかったため、混同行列の計算と表示をスキップしました。\")\n","\n","\n","# NameError は model, data_module, config_path, config が未定義の場合\n","# FileNotFoundError は設定ファイルが見つからない場合（configロード時）\n","# KeyError は config 辞書に必要なキーがない場合\n","# ImportError はモジュールインポート失敗時\n","# StopIteration はデータローダーが空の場合\n","except (NameError, FileNotFoundError, KeyError, ImportError, StopIteration) as e:\n","     print(f\"混同行列の計算に必要な変数、設定、またはデータが見つかりません: {e}\")\n","# 広範な例外捕捉は避ける\n","except Exception as e: # より具体的な例外を捕捉することが望ましい\n","    print(f\"混同行列の計算または表示中に予期せぬエラーが発生しました: {e}\")\n","    import traceback\n","    traceback.print_exc()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.9.19"}},"nbformat":4,"nbformat_minor":0}