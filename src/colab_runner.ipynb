{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BKueD3etSvyt"
   },
   "source": [
    "# EfficientNet_B4 Classifier Training\n",
    "\n",
    "このノートブックはNFNetモデルの訓練を実行するためのものです。PyTorch Lightningを使用した学習フレームワークで、転移学習による画像分類を行います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ejvXESjtSvyt"
   },
   "source": [
    "## Google Driveのマウント"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24022,
     "status": "ok",
     "timestamp": 1747396446763,
     "user": {
      "displayName": "土倉恵一郎",
      "userId": "13053641895557367934"
     },
     "user_tz": -540
    },
    "id": "kAL5Z5BNSvyu",
    "outputId": "a6768f3c-4e19-4611-f1a1-b06029d2a8d2"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Google Colab環境かどうかを判定\n",
    "IN_COLAB = 'google.colab' in str(get_ipython())\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"Google Colab環境を検出しました。\")\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    # プロジェクトディレクトリに移動\n",
    "    project_dir = '/content/drive/MyDrive/Time_Series_Classifier'\n",
    "    # %cd はノートブックのセルマジックなので、os.chdirを使用\n",
    "    if os.getcwd() != project_dir:\n",
    "        os.chdir(project_dir)\n",
    "        print(f\"Moved to: {os.getcwd()}\")\n",
    "    # srcディレクトリをパスに追加 (main.pyと同じ階層にある場合)\n",
    "    # main.pyがプロジェクトルートにあるため、srcは不要かもしれないが念のため\n",
    "    src_dir = os.path.join(project_dir, 'src')\n",
    "    if src_dir not in sys.path:\n",
    "        sys.path.insert(0, src_dir)\n",
    "    # configsディレクトリもパスに追加 (config_utilsのため)\n",
    "    configs_dir = os.path.join(project_dir, 'configs')\n",
    "    if configs_dir not in sys.path:\n",
    "        sys.path.insert(0, configs_dir)\n",
    "else:\n",
    "    print(\"ローカル環境を検出しました。\")\n",
    "    # ローカルのプロジェクトディレクトリを設定\n",
    "    project_dir = 'i:/Efficient_Net_Classifier'\n",
    "    # カレントディレクトリがプロジェクトディレクトリでない場合は移動\n",
    "    if os.getcwd() != os.path.abspath(project_dir):\n",
    "        os.chdir(project_dir)\n",
    "        print(f\"Moved to: {os.getcwd()}\")\n",
    "    # srcディレクトリをパスに追加\n",
    "    src_dir = os.path.join(project_dir, 'src')\n",
    "    if src_dir not in sys.path:\n",
    "        sys.path.insert(0, src_dir)\n",
    "    # configsディレクトリもパスに追加\n",
    "    configs_dir = os.path.join(project_dir, 'configs')\n",
    "    if configs_dir not in sys.path:\n",
    "        sys.path.insert(0, configs_dir)\n",
    "\n",
    "print(f\"現在のディレクトリ: {os.getcwd()}\")\n",
    "print(f\"プロジェクトディレクトリ: {project_dir}\")\n",
    "print(f\"Pythonパスにsrcを追加: {src_dir in sys.path}\")\n",
    "print(f\"Pythonパスにconfigsを追加: {configs_dir in sys.path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CXOntyfISvyu"
   },
   "source": [
    "## 必要なライブラリのインストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 67053,
     "status": "ok",
     "timestamp": 1747396513819,
     "user": {
      "displayName": "土倉恵一郎",
      "userId": "13053641895557367934"
     },
     "user_tz": -540
    },
    "id": "A-aYt6TOSvyu",
    "outputId": "e2e9985d-7ea5-4342-c685-a90a2cf357df"
   },
   "outputs": [],
   "source": [
    "# requirements.txtからインストール\n",
    "# !pip install torch torchvision pytorch-lightning torchmetrics PyYAML scikit-learn pandas\n",
    "! pip install lightning torchmetrics timm seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jmMDBUz7Svyu"
   },
   "source": [
    "## GPUの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3221,
     "status": "ok",
     "timestamp": 1747396517042,
     "user": {
      "displayName": "土倉恵一郎",
      "userId": "13053641895557367934"
     },
     "user_tz": -540
    },
    "id": "zNZqVM0NSvyu",
    "outputId": "722603d9-ee2b-4c2b-edab-df23a6399a11"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "print(f\"CUDA利用可能: {torch.cuda.is_available()}\")\n",
    "print(f\"利用可能なGPU数: {torch.cuda.device_count()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"現在のGPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5qRspzfUSvyv"
   },
   "source": [
    "## データセットの確認（オプション）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TDRREmebSvyv"
   },
   "outputs": [],
   "source": [
    "# # データセットの構造確認（オプション）\n",
    "# !ls -la /content/drive/MyDrive/Time_Series_Classifier/data/dataset_a_15m_winsize40/train\n",
    "# # 各クラスの画像数を確認\n",
    "# !find /content/drive/MyDrive/Time_Series_Classifier/data/dataset_a_15m_winsize40/train -type f | grep -v \"/__\" | sort | cut -d/ -f8 | uniq -c\n",
    "# !find /content/drive/MyDrive/Time_Series_Classifier/data/dataset_a_15m_winsize40/test -type f | grep -v \"/__\" | sort | cut -d/ -f8 | uniq -c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ouV1lwOISvyv"
   },
   "source": [
    "## 設定ファイルの確認と編集（必要に応じて）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 875,
     "status": "ok",
     "timestamp": 1747396517924,
     "user": {
      "displayName": "土倉恵一郎",
      "userId": "13053641895557367934"
     },
     "user_tz": -540
    },
    "id": "muEkxJTbSvyv",
    "outputId": "14a6c93e-bbce-485b-a527-9fda8667e546"
   },
   "outputs": [],
   "source": [
    "# 設定ファイルの内容確認\n",
    "import yaml\n",
    "import os\n",
    "import platform\n",
    "\n",
    "# 環境に応じた設定ファイルパスを設定\n",
    "if IN_COLAB:\n",
    "    config_filename = 'config_for_google_colab.yaml'\n",
    "else:\n",
    "    config_filename = 'config.yaml' # ローカル用の設定ファイル\n",
    "\n",
    "config_path = os.path.join(project_dir, 'configs', config_filename)\n",
    "print(f\"使用する設定ファイル: {config_path}\")\n",
    "\n",
    "# 設定ファイルの内容確認\n",
    "try:\n",
    "    with open(config_path, 'r', encoding='utf-8') as f:\n",
    "        print(\"--- 設定ファイル内容 ---\")\n",
    "        print(f.read())\n",
    "        print(\"----------------------\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"エラー: 設定ファイル {config_path} が見つかりません。パスを確認してください。\")\n",
    "# 広範な例外捕捉は避ける (例: yaml.YAMLError など、より具体的な例外を捕捉する)\n",
    "except yaml.YAMLError as e:\n",
    "    print(f\"設定ファイルの解析中にエラーが発生しました: {e}\")\n",
    "except IOError as e:\n",
    "    print(f\"設定ファイルの読み込み中にI/Oエラーが発生しました: {e}\")\n",
    "\n",
    "# --- 注意 ---\n",
    "# 設定の変更は直接YAMLファイルを編集するか、main.py側で行います。\n",
    "# このノートブックでは設定の読み込み確認のみを行います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YkiA_EhmSvyv"
   },
   "source": [
    "## Windows環境での注意事項\n",
    "\n",
    "Windows環境では、Pythonのマルチプロセッシングの仕組み上の制約から、`num_workers` を0以外に設定するとエラーが発生しやすくなります。これは主に以下の理由によります：\n",
    "\n",
    "- **プロセス生成方法の違い**: LinuxなどのUnix系OSでは、フォーク（`fork`）システムコールを使ってプロセスを生成するため、親プロセスの状態をそのままコピーできます。一方、Windowsでは `spawn` メソッドが使われます。`spawn` は新しいプロセスを最初から初期化するため、親プロセス上で定義された状態やグローバル変数が継承されず、必要な初期化手順を踏む必要があります。\n",
    "\n",
    "- **`if __name__ == \"__main__\":` の重要性**: Windowsでは、コードが必ずこのブロック内で実行されるように構成する必要があります。\n",
    "\n",
    "- **Jupyter環境の制約**: 特にJupyter環境でのマルチプロセスはWindows上で問題を起こしやすいです。\n",
    "\n",
    "このノートブックでは、Windows環境を自動検出して `num_workers=0` に設定するようにしています。**パフォーマンスを最大化するには、Google Colab環境での実行を推奨します。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U2Y51_izSvyv"
   },
   "source": [
    "## 訓練スクリプトの実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "vHYM5bpySvyv"
   },
   "outputs": [],
   "source": [
    "# main.py を実行して訓練を開始\n",
    "# main.py は内部で環境を判断し、適切な設定ファイルを読み込みます\n",
    "print(f\"プロジェクトディレクトリ ({project_dir}) で main.py を実行します...\")\n",
    "# !python main.py コマンドを実行\n",
    "# ノートブック環境からPythonスクリプトを実行する場合、カレントディレクトリに注意\n",
    "# 上のセルで os.chdir を使ってプロジェクトディレクトリに移動済みのはず\n",
    "! python main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SwW6xwbpSvyv"
   },
   "source": [
    "## TensorBoardによる訓練の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "vAfpBU9cSvyv"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# config_utils.py が configs ディレクトリにあることを確認\n",
    "try:\n",
    "    # src と configs が sys.path にあるため、直接インポート\n",
    "    from config_utils import load_config # config読み込み用ユーティリティ\n",
    "except ImportError:\n",
    "    print(\"エラー: config_utils が見つかりません。Pythonパスを確認してください。\")\n",
    "    # 必要であればパスを再度追加\n",
    "    configs_dir = os.path.join(project_dir, 'configs')\n",
    "    if configs_dir not in sys.path:\n",
    "        sys.path.insert(0, configs_dir)\n",
    "        print(f\"'{configs_dir}' をPythonパスに追加しました。\")\n",
    "        try:\n",
    "            from config_utils import load_config\n",
    "        except ImportError as ie:\n",
    "             print(f\"再試行しましたが、config_utils のインポートに失敗しました: {ie}\")\n",
    "             # ここで処理を中断するか、デフォルトパスを使うなどの代替策を検討\n",
    "             raise ie # エラーを再発生させる\n",
    "\n",
    "# 設定ファイルを再度読み込み、ログディレクトリを取得\n",
    "try:\n",
    "    # config_path が前のセルで定義されていることを確認\n",
    "    if 'config_path' not in globals():\n",
    "        raise NameError(\"'config_path' is not defined. Please run the cell defining it.\")\n",
    "    config = load_config(config_path)\n",
    "    # log_dir_tb = config.get(\"logs_dir\", os.path.join(project_dir, \"logs\")) # 設定ファイルから取得する代わりに、期待されるパスを直接構築\n",
    "    experiment_name = \"stock_classifier\" # main.pyでの設定と合わせる\n",
    "    # 正しいログディレクトリのベースパスを構築\n",
    "    correct_log_base_dir = os.path.join(project_dir, \"logs\")\n",
    "    tensorboard_logdir = os.path.join(correct_log_base_dir, experiment_name) # 常に logs/stock_classifier を指すように修正\n",
    "\n",
    "    # Colab用のTensorBoard拡張を読み込む\n",
    "    if IN_COLAB:\n",
    "        %load_ext tensorboard\n",
    "        print(f\"TensorBoard ログディレクトリ: {tensorboard_logdir}\")\n",
    "        # パスにスペースが含まれる可能性を考慮して引用符で囲む\n",
    "        %tensorboard --logdir=\"{tensorboard_logdir}\"\n",
    "    else:\n",
    "        print(\"ローカル環境です。TensorBoardを手動で起動してください:\")\n",
    "        # Windowsの場合、パスをダブルクォーテーションで囲むのが一般的\n",
    "        print(f\"tensorboard --logdir=\\\"{tensorboard_logdir}\\\"\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"エラー: 設定ファイル {config_path} が見つかりません。\")\n",
    "except NameError as e:\n",
    "    print(f\"エラー: 必要な変数(config_pathなど)が定義されていません - {e}\")\n",
    "except KeyError as e:\n",
    "    print(f\"エラー: 設定ファイルに必要なキー ('logs_dir'など) がありません - {e}\")\n",
    "# 広範な例外捕捉は避ける\n",
    "except Exception as e: # より具体的な例外を捕捉することが望ましい\n",
    "    print(f\"TensorBoardの準備中に予期せぬエラーが発生しました: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "8bd4_7xBx3-D"
   },
   "outputs": [],
   "source": [
    "# 新しいセルに追加するコード\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import yaml # yaml をインポート\n",
    "\n",
    "# config_utils が見つからない場合に備えてパスを追加\n",
    "# project_dir は ID '9f53d608' のセルで定義されている想定\n",
    "try:\n",
    "    from configs.config_utils import load_config, get_project_root\n",
    "except ImportError:\n",
    "    print(\"config_utils が見つかりません。パスを確認・追加します。\")\n",
    "    configs_dir_util = os.path.join(project_dir, 'configs')\n",
    "    if configs_dir_util not in sys.path:\n",
    "        sys.path.insert(0, configs_dir_util)\n",
    "        print(f\"'{configs_dir_util}' をPythonパスに追加しました。\")\n",
    "        try:\n",
    "            from configs.config_utils import load_config, get_project_root\n",
    "        except ImportError as ie_util:\n",
    "            print(f\"再試行しましたが、config_utils のインポートに失敗しました: {ie_util}\")\n",
    "            raise ie_util # エラーを再発生\n",
    "\n",
    "# find_best_checkpoint 関数の定義 (evaluate.py/visualize.py と同じもの)\n",
    "def find_best_checkpoint(config, metric=\"f1\"):\n",
    "    \"\"\"\n",
    "    指定されたメトリックに基づいて最適なチェックポイントファイルを見つける。\n",
    "    新しいディレクトリ構造とファイル名形式に対応。\n",
    "\n",
    "    Args:\n",
    "        config (dict): 設定辞書。'model_mode', 'model_architecture_name' を含む。\n",
    "        metric (str): 最適化するメトリック ('f1' または 'loss')。\n",
    "\n",
    "    Returns:\n",
    "        str or None: 最適なチェックポイントファイルのパス。見つからない場合はNone。\n",
    "    \"\"\"\n",
    "    # project_root は get_project_root() で取得するか、ノートブックの project_dir を使う\n",
    "    # ここでは get_project_root() を使う\n",
    "    try:\n",
    "        project_root = get_project_root()\n",
    "    except Exception as e_proj_root:\n",
    "         print(f\"get_project_root() でエラー: {e_proj_root}. ノートブックの 'project_dir' を使用します。\")\n",
    "         # project_dir がグローバルスコープにあることを期待\n",
    "         if 'project_dir' not in globals():\n",
    "              print(\"エラー: 'project_dir' 変数が定義されていません。\")\n",
    "              return None\n",
    "         project_root = project_dir\n",
    "\n",
    "    model_mode = config.get(\"model_mode\", \"single\")\n",
    "    model_architecture_name = config.get(\"model_architecture_name\", \"default_model\")\n",
    "    # 新しいチェックポイントディレクトリパスを構築\n",
    "    # config から checkpoint_dir を取得し、その下に model_mode/model_architecture_name を追加\n",
    "    base_checkpoint_dir = config.get(\"checkpoint_dir\", os.path.join(project_root, \"checkpoints\"))\n",
    "    checkpoint_dir = os.path.join(base_checkpoint_dir, model_mode, model_architecture_name)\n",
    "\n",
    "    print(f\"チェックポイントディレクトリを検索中: {checkpoint_dir}\")\n",
    "\n",
    "    if not os.path.isdir(checkpoint_dir):\n",
    "        print(f\"エラー: チェックポイントディレクトリが見つかりません: {checkpoint_dir}\")\n",
    "        # 設定ファイルで指定された base_checkpoint_dir も確認\n",
    "        if base_checkpoint_dir != checkpoint_dir and os.path.isdir(base_checkpoint_dir):\n",
    "             print(f\"警告: サブディレクトリ '{model_mode}/{model_architecture_name}' はありませんが、ベースディレクトリ '{base_checkpoint_dir}' は存在します。\")\n",
    "             # ベースディレクトリ内も検索するかどうか？ -> ここではしない\n",
    "        return None\n",
    "\n",
    "    # 新しいファイル名形式 'epoch={epoch:05d}-val_loss={val_loss:.4f}-val_f1={val_f1:.4f}.ckpt'\n",
    "    # metric に応じた正規表現パターン\n",
    "    if metric == \"f1\":\n",
    "        # val_f1 を抽出するパターン\n",
    "        pattern = re.compile(r'epoch=(\\d+)-val_loss=([\\d.]+)-val_f1=([\\d.]+)\\.ckpt')\n",
    "        metric_index = 2 # F1スコアは3番目のキャプチャグループ (0-based index)\n",
    "        best_metric_val = -1.0 # F1スコアは高いほど良い\n",
    "        compare_func = lambda current, best: current > best\n",
    "    elif metric == \"loss\":\n",
    "        # val_loss を抽出するパターン\n",
    "        pattern = re.compile(r'epoch=(\\d+)-val_loss=([\\d.]+)-val_f1=([\\d.]+)\\.ckpt')\n",
    "        metric_index = 1 # 損失は2番目のキャプチャグループ\n",
    "        best_metric_val = float('inf') # 損失は低いほど良い\n",
    "        compare_func = lambda current, best: current < best\n",
    "    else:\n",
    "        print(f\"エラー: 未知のメトリック '{metric}'。'f1' または 'loss' を使用してください。\")\n",
    "        return None\n",
    "\n",
    "    best_checkpoint_path = None\n",
    "    found_checkpoints = []\n",
    "    last_ckpt_path = None # last.ckpt のパスを初期化\n",
    "\n",
    "    try:\n",
    "        for filename in os.listdir(checkpoint_dir):\n",
    "            match = pattern.match(filename)\n",
    "            if match:\n",
    "                found_checkpoints.append(filename)\n",
    "                try:\n",
    "                    # 指定されたメトリックの値を抽出\n",
    "                    current_metric_val = float(match.group(metric_index + 1)) # グループインデックスは1から始まるため+1\n",
    "                    print(f\"  チェックポイント '{filename}' の {metric}: {current_metric_val}\")\n",
    "                    # 最良のメトリック値を更新\n",
    "                    if compare_func(current_metric_val, best_metric_val):\n",
    "                        best_metric_val = current_metric_val\n",
    "                        best_checkpoint_path = os.path.join(checkpoint_dir, filename)\n",
    "                except (ValueError, IndexError) as e:\n",
    "                    print(f\"  警告: ファイル '{filename}' のメトリック値の解析中にエラー: {e}\")\n",
    "                    continue\n",
    "            # 'last.ckpt' も候補として保持 (最良が見つからない場合に使用)\n",
    "            elif filename == \"last.ckpt\":\n",
    "                 last_ckpt_path = os.path.join(checkpoint_dir, filename)\n",
    "\n",
    "    except OSError as e:\n",
    "        print(f\"エラー: チェックポイントディレクトリの読み取り中にエラーが発生しました: {e}\")\n",
    "        return None\n",
    "\n",
    "    if best_checkpoint_path:\n",
    "        print(f\"最適な {metric} ({best_metric_val:.4f}) を持つチェックポイントが見つかりました: {best_checkpoint_path}\")\n",
    "        return best_checkpoint_path\n",
    "    elif last_ckpt_path and os.path.exists(last_ckpt_path): # last_ckpt_path が None でないことを確認\n",
    "         print(f\"警告: 最適な {metric} を持つチェックポイントが見つかりませんでした。'last.ckpt' を使用します: {last_ckpt_path}\")\n",
    "         return last_ckpt_path\n",
    "    else:\n",
    "        print(f\"警告: 有効なチェックポイントファイルがディレクトリ '{checkpoint_dir}' に見つかりませんでした。\")\n",
    "        # last.ckpt も見つからなかった場合、古い形式のチェックポイントをベースディレクトリで探す試み（オプション）\n",
    "        print(f\"念のため、ベースディレクトリ '{base_checkpoint_dir}' で古い形式の 'last.ckpt' を探します...\")\n",
    "        old_last_ckpt = os.path.join(base_checkpoint_dir, 'last.ckpt')\n",
    "        if os.path.exists(old_last_ckpt):\n",
    "             print(f\"警告: ベースディレクトリで古い形式の 'last.ckpt' を見つけました。これを使用します: {old_last_ckpt}\")\n",
    "             return old_last_ckpt\n",
    "        else:\n",
    "             print(f\"警告: ベースディレクトリにも 'last.ckpt' が見つかりませんでした。\")\n",
    "             return None\n",
    "\n",
    "print(\"find_best_checkpoint 関数が定義されました。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rSWUFAx_Svyv"
   },
   "source": [
    "## 学習済みモデルのテストと評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "XujtP7ooSvyw"
   },
   "outputs": [],
   "source": [
    "# 学習後、最良のモデルを使って評価を実行するには\n",
    "# すでにテストは訓練時に実行されているはずですが、個別に実行したい場合は以下を利用\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import lightning.pytorch as pl # lightning に変更\n",
    "import re\n",
    "\n",
    "# モジュールパスの確認 (必要であれば)\n",
    "# 最初のセルで追加済みのはずだが、念のため確認・追加\n",
    "project_root_dir_test = os.path.abspath(os.path.join(os.getcwd())) # main.pyと同じ階層を想定\n",
    "src_dir_test = os.path.join(project_root_dir_test, 'src')\n",
    "configs_dir_test = os.path.join(project_root_dir_test, 'configs')\n",
    "\n",
    "if src_dir_test not in sys.path:\n",
    "    sys.path.insert(0, src_dir_test)\n",
    "if configs_dir_test not in sys.path:\n",
    "     sys.path.insert(0, configs_dir_test)\n",
    "\n",
    "try:\n",
    "    # src と configs が sys.path にあるため、直接インポート\n",
    "    from model import StockClassifier\n",
    "    from datamodule import StockDataModule\n",
    "    from config_utils import load_config\n",
    "except ImportError as e:\n",
    "    print(f\"必要なモジュールのインポートに失敗しました: {e}\")\n",
    "    print(\"モジュールパスを確認してください。sys.path:\", sys.path)\n",
    "    # インポート失敗時は処理を中断\n",
    "    raise e\n",
    "\n",
    "try:\n",
    "    # 設定ファイルの読み込み（訓練時と同じものを使用）\n",
    "    # config_path は前のセルで定義されている想定\n",
    "    if 'config_path' not in globals():\n",
    "        # config_path が未定義の場合、環境に応じて再設定\n",
    "        if IN_COLAB:\n",
    "            config_filename_test = 'config_for_google_colab.yaml'\n",
    "        else:\n",
    "            config_filename_test = 'config.yaml'\n",
    "        config_path = os.path.join(project_root_dir_test, 'configs', config_filename_test)\n",
    "        print(f\"警告: 'config_path' が未定義でした。'{config_path}' を使用します。\")\n",
    "\n",
    "    config = load_config(config_path)\n",
    "\n",
    "    # 最良モデルのチェックポイントパスを取得\n",
    "    # configからcheckpoint_dirを取得、なければデフォルトパス\n",
    "    checkpoint_dir_path = config.get(\"checkpoint_dir\", os.path.join(project_root_dir_test, \"checkpoints\"))\n",
    "    print(f\"チェックポイントディレクトリ: {checkpoint_dir_path}\")\n",
    "\n",
    "    # ModelCheckpointで設定したファイル名パターンに基づいて探す\n",
    "    # val_f1 が最高のモデルを探す (mode='max')\n",
    "    # ファイル名形式: 'model_epoch_{epoch:05d}_val_loss_{val_loss:.4f}_val_f1_{val_f1:.4f}.ckpt'\n",
    "    checkpoints = []\n",
    "    if os.path.isdir(checkpoint_dir_path):\n",
    "        checkpoints = [f for f in os.listdir(checkpoint_dir_path) if f.startswith(\"model_epoch_\") and \"val_f1_\" in f and f.endswith(\".ckpt\")]\n",
    "    else:\n",
    "        print(f\"エラー: チェックポイントディレクトリが見つかりません: {checkpoint_dir_path}\")\n",
    "\n",
    "    best_checkpoint_path = None\n",
    "    best_f1 = -1.0\n",
    "\n",
    "    if checkpoints:\n",
    "        print(f\"見つかったチェックポイント候補: {checkpoints}\")\n",
    "        # 正規表現を使用してファイル名からval_f1の値を抽出\n",
    "        f1_pattern = re.compile(r'val_f1_([0-9.]+)')\n",
    "        for fname in checkpoints:\n",
    "            try:\n",
    "                # 正規表現でF1スコアを抽出 (例: model_epoch_00011_val_loss_0.9229_val_f1_0.6907.ckpt → 0.6907)\n",
    "                f1_match = f1_pattern.search(fname)\n",
    "                if f1_match:\n",
    "                    current_f1 = float(f1_match.group(1))\n",
    "                    print(f\"  チェックポイント '{fname}' の F1スコア: {current_f1}\")\n",
    "                    if current_f1 > best_f1:\n",
    "                        best_f1 = current_f1\n",
    "                        best_checkpoint_path = os.path.join(checkpoint_dir_path, fname)\n",
    "                else:\n",
    "                    print(f\"  警告: ファイル '{fname}' からF1スコアを抽出できませんでした (パターンに一致しない)\")\n",
    "            except (ValueError, AttributeError) as parse_err:\n",
    "                print(f\"  警告: ファイル '{fname}' の解析中にエラーが発生しました: {parse_err}\")\n",
    "                continue # 次のファイルへ\n",
    "        if best_checkpoint_path:\n",
    "             print(f\"最高のF1スコア ({best_f1:.4f}) を持つチェックポイントが見つかりました: {best_checkpoint_path}\")\n",
    "        else:\n",
    "             print(\"F1スコアを含む有効なチェックポイントが見つかりませんでした。\")\n",
    "\n",
    "    # 最良が見つからない場合は last.ckpt を試す\n",
    "    if best_checkpoint_path is None:\n",
    "        last_ckpt = os.path.join(checkpoint_dir_path, 'last.ckpt')\n",
    "        if os.path.exists(last_ckpt):\n",
    "            best_checkpoint_path = last_ckpt\n",
    "            print(f\"最良のF1チェックポイントが見つかりません。最新のチェックポイントを使用します: {best_checkpoint_path}\")\n",
    "        else:\n",
    "             # last.ckpt も見つからない場合\n",
    "             print(f\"エラー: 評価に使用できるチェックポイント ('model_e...val_f1...' または 'last.ckpt') がディレクトリ '{checkpoint_dir_path}' に見つかりません。\")\n",
    "             # エラーにするか、Noneのまま進むかは要件次第\n",
    "             # ここでは None のまま進み、後続のifで処理する\n",
    "\n",
    "    if best_checkpoint_path:\n",
    "        print(f\"評価に使用するチェックポイント: {best_checkpoint_path}\")\n",
    "        # データモジュールの準備（テスト用）\n",
    "        data_module = StockDataModule(config)\n",
    "        # data_module.setup(\"test\") # testメソッド内で自動的に呼ばれる\n",
    "\n",
    "        # モデルのロード\n",
    "        # configを渡して、チェックポイント保存時と異なる可能性のある設定に対応\n",
    "        # strict=False は、モデル構造が変わっていない限り、一部の不一致を許容する\n",
    "        try:\n",
    "            model = StockClassifier.load_from_checkpoint(best_checkpoint_path, config=config, strict=False)\n",
    "            print(\"モデルのロードに成功しました。\")\n",
    "        except FileNotFoundError as model_load_err:\n",
    "            print(f\"エラー: チェックポイントファイルが見つかりません: {model_load_err}\")\n",
    "            raise model_load_err\n",
    "        except Exception as model_load_err: # より具体的な例外捕捉が望ましい\n",
    "            print(f\"モデルのロード中にエラーが発生しました: {model_load_err}\")\n",
    "            raise model_load_err\n",
    "\n",
    "        # テスト用トレーナーの設定\n",
    "        # accelerator と devices を config や環境に合わせて設定\n",
    "        accelerator_setting = \"auto\"\n",
    "        devices_setting = \"auto\"\n",
    "        if config.get(\"force_gpu\", False) and torch.cuda.is_available():\n",
    "            accelerator_setting = \"gpu\"\n",
    "            devices_setting = 1 # テストは通常1デバイス\n",
    "        elif config.get(\"force_cpu\", False):\n",
    "            accelerator_setting = \"cpu\"\n",
    "            devices_setting = 1\n",
    "\n",
    "        tester = pl.Trainer(\n",
    "            accelerator=accelerator_setting,\n",
    "            devices=devices_setting,\n",
    "            logger=False, # テスト結果はログ不要\n",
    "            precision=config.get('precision', '32-true') # 訓練時と同じ精度を使用\n",
    "        )\n",
    "\n",
    "        # テストの実行\n",
    "        print(\"\\nテストを再実行します...\")\n",
    "        try:\n",
    "            test_results = tester.test(model, datamodule=data_module)\n",
    "            print(\"\\nテスト結果:\")\n",
    "            print(test_results)\n",
    "        except Exception as test_err: # より具体的な例外捕捉が望ましい\n",
    "             print(f\"テストの実行中にエラーが発生しました: {test_err}\")\n",
    "             import traceback\n",
    "             traceback.print_exc()\n",
    "\n",
    "    else:\n",
    "        # best_checkpoint_path が None の場合（チェックポイントが見つからなかった場合）\n",
    "        print(\"テストを実行できませんでした。有効なチェックポイントが見つかりません。\")\n",
    "\n",
    "# FileNotFoundError は設定ファイル読み込み時に発生する可能性\n",
    "# KeyError は config 辞書に必要なキーがない場合に発生する可能性\n",
    "# NameError は config_path など、前のセルで定義されるべき変数が未定義の場合\n",
    "# ImportError はモジュールインポート失敗時\n",
    "except (FileNotFoundError, KeyError, NameError, ImportError) as e:\n",
    "    print(f\"エラーが発生しました: {e}\")\n",
    "# 広範な例外捕捉は避ける\n",
    "except Exception as e: # より具体的な例外を捕捉することが望ましい\n",
    "    print(f\"テスト準備または実行中に予期せぬエラーが発生しました: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9bhU03pqSvyw"
   },
   "source": [
    "## モデル予測の可視化（オプション）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 169477,
     "status": "error",
     "timestamp": 1747394216157,
     "user": {
      "displayName": "土倉恵一郎",
      "userId": "13053641895557367934"
     },
     "user_tz": -540
    },
    "id": "N_YxUYiImK13",
    "outputId": "6939f521-f16b-43e9-9587-a74f27d07f6f"
   },
   "outputs": [],
   "source": [
    "# 必要な変数が定義されているか確認し、なければ再定義/ロード\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import re\n",
    "\n",
    "# モジュールパスの確認 (必要であれば)\n",
    "# 最初のセルで追加済みのはずだが、念のため確認・追加\n",
    "project_root_dir_vis = os.path.abspath(os.path.join(os.getcwd()))\n",
    "src_dir_vis = os.path.join(project_root_dir_vis, 'src')\n",
    "configs_dir_vis = os.path.join(project_root_dir_vis, 'configs')\n",
    "\n",
    "if src_dir_vis not in sys.path:\n",
    "    sys.path.insert(0, src_dir_vis)\n",
    "if configs_dir_vis not in sys.path:\n",
    "     sys.path.insert(0, configs_dir_vis)\n",
    "\n",
    "# グローバルスコープに変数が存在するかチェック\n",
    "# 存在しない場合のみ再ロードを試みる\n",
    "if 'data_module' not in globals() or 'model' not in globals():\n",
    "    print(\"data_module または model が未定義です。再定義/再ロードを試みます...\")\n",
    "    try:\n",
    "        # src と configs が sys.path にあるため、直接インポート\n",
    "        from model import StockClassifier\n",
    "        from datamodule import StockDataModule\n",
    "        from config_utils import load_config\n",
    "\n",
    "        # 設定ファイルの読み込み\n",
    "        # config_path は前のセルで定義されている想定\n",
    "        if 'config_path' not in globals():\n",
    "            # config_path が未定義の場合、環境に応じて再設定\n",
    "            if IN_COLAB:\n",
    "                config_filename_vis = 'config_for_google_colab.yaml'\n",
    "            else:\n",
    "                config_filename_vis = 'config.yaml'\n",
    "            config_path = os.path.join(project_root_dir_vis, 'configs', config_filename_vis)\n",
    "            print(f\"警告: 'config_path' が未定義でした。'{config_path}' を使用します。\")\n",
    "\n",
    "        config = load_config(config_path)\n",
    "        # データモジュールの準備\n",
    "        data_module = StockDataModule(config)\n",
    "        # 可視化にはテストデータを使うことが多いので 'test' を指定\n",
    "        # setup() は dataloader() 呼び出し時に内部で実行される場合もあるが、明示的に呼ぶ\n",
    "        data_module.setup('test')\n",
    "        print(\"DataModuleをセットアップしました (stage='test')。\")\n",
    "\n",
    "        # モデルのロード（前のセルで特定した最良または最新のチェックポイントから）\n",
    "        # best_checkpoint_path が前のセルで定義されていることを期待\n",
    "        if 'best_checkpoint_path' in globals() and best_checkpoint_path and os.path.exists(best_checkpoint_path):\n",
    "             print(f\"前のセルで特定されたチェックポイントを使用します: {best_checkpoint_path}\")\n",
    "             model = StockClassifier.load_from_checkpoint(best_checkpoint_path, config=config, strict=False)\n",
    "             print(f\"モデルを {best_checkpoint_path} からロードしました。\")\n",
    "        else:\n",
    "             # best_checkpoint_path が未定義または無効な場合、再度探す\n",
    "             print(\"警告: 'best_checkpoint_path' が未定義または無効です。再度チェックポイントを探します...\")\n",
    "             checkpoint_dir_path_vis = config.get(\"checkpoint_dir\", os.path.join(project_root_dir_vis, \"checkpoints\"))\n",
    "             # 前のセルと同様のロジックで最良チェックポイントを探す\n",
    "             checkpoints_vis = []\n",
    "             if os.path.isdir(checkpoint_dir_path_vis):\n",
    "                 checkpoints_vis = [f for f in os.listdir(checkpoint_dir_path_vis) if f.startswith(\"model_epoch_\") and \"val_f1_\" in f and f.endswith(\".ckpt\")]\n",
    "             temp_best_path = None\n",
    "             temp_best_f1 = -1.0\n",
    "             if checkpoints_vis:\n",
    "                 print(f\"見つかったチェックポイント候補: {checkpoints_vis}\")\n",
    "                 # 正規表現を使用してファイル名からval_f1の値を抽出\n",
    "                 f1_pattern = re.compile(r'val_f1_([0-9.]+)')\n",
    "                 for fname in checkpoints_vis:\n",
    "                     try:\n",
    "                         # 正規表現でF1スコアを抽出 (例: model_epoch_00011_val_loss_0.9229_val_f1_0.6907.ckpt → 0.6907)\n",
    "                         f1_match = f1_pattern.search(fname)\n",
    "                         if f1_match:\n",
    "                             current_f1 = float(f1_match.group(1))\n",
    "                             print(f\"  チェックポイント '{fname}' の F1スコア: {current_f1}\")\n",
    "                             if current_f1 > temp_best_f1:\n",
    "                                 temp_best_f1 = current_f1\n",
    "                                 temp_best_path = os.path.join(checkpoint_dir_path_vis, fname)\n",
    "                         else:\n",
    "                             print(f\"  警告: ファイル '{fname}' からF1スコアを抽出できませんでした (パターンに一致しない)\")\n",
    "                     except (ValueError, AttributeError) as parse_err:\n",
    "                         print(f\"  警告: ファイル '{fname}' の解析中にエラーが発生しました: {parse_err}\")\n",
    "                         continue # 次のファイルへ\n",
    "             if temp_best_path:\n",
    "                 best_checkpoint_path = temp_best_path # グローバル変数も更新\n",
    "                 print(f\"最高のF1スコア ({temp_best_f1:.4f}) を持つチェックポイントを再検出しました: {best_checkpoint_path}\")\n",
    "                 model = StockClassifier.load_from_checkpoint(best_checkpoint_path, config=config, strict=False)\n",
    "                 print(f\"モデルを {best_checkpoint_path} からロードしました。\")\n",
    "             else:\n",
    "                 last_ckpt_vis = os.path.join(checkpoint_dir_path_vis, 'last.ckpt')\n",
    "                 if os.path.exists(last_ckpt_vis):\n",
    "                     best_checkpoint_path = last_ckpt_vis # グローバル変数も更新\n",
    "                     print(f\"最良が見つからず、最新のモデルを使用します: {best_checkpoint_path}\")\n",
    "                     model = StockClassifier.load_from_checkpoint(best_checkpoint_path, config=config, strict=False)\n",
    "                     print(f\"モデルを {best_checkpoint_path} からロードしました。\")\n",
    "                 else:\n",
    "                     print(f\"エラー: ロードするモデルのチェックポイントがディレクトリ '{checkpoint_dir_path_vis}' に見つかりません。\")\n",
    "                     raise FileNotFoundError(f\"チェックポイントが見つかりません in {checkpoint_dir_path_vis}\")\n",
    "\n",
    "    # ImportError はモジュールが見つからない場合\n",
    "    # FileNotFoundError は設定ファイルやチェックポイントが見つからない場合\n",
    "    # NameError は config_path などが未定義の場合\n",
    "    except (ImportError, FileNotFoundError, NameError) as e:\n",
    "        print(f\"エラーが発生しました: {e}\")\n",
    "        # エラー発生時は以降のセルが実行できないため、再発生させる\n",
    "        raise e\n",
    "    # 広範な例外捕捉は避ける\n",
    "    except Exception as e: # より具体的な例外を捕捉することが望ましい\n",
    "        print(f\"可視化のための再定義/再ロード中に予期せぬエラーが発生しました: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        # エラー発生時は以降のセルが実行できないため、再発生させる\n",
    "        raise e\n",
    "else:\n",
    "    print(\"data_module と model は既に定義済みです。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uLBX4KDXSvyw"
   },
   "outputs": [],
   "source": [
    "# テストデータから数サンプルを選び、予測結果を可視化する\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "\n",
    "try:\n",
    "    # 設定ファイルからクラス名と正規化パラメータを取得\n",
    "    # config がロードされていることを確認\n",
    "    if 'config' not in globals():\n",
    "        # config がなければロードを試みる\n",
    "        print(\"警告: 'config' が未定義です。ロードを試みます...\")\n",
    "        configs_dir_vis2 = os.path.join(project_dir, 'configs') # project_dir は最初のセルで定義済みのはず\n",
    "        if configs_dir_vis2 not in sys.path:\n",
    "             sys.path.insert(0, configs_dir_vis2)\n",
    "        try:\n",
    "            from config_utils import load_config\n",
    "        except ImportError as ie:\n",
    "             print(f\"config_utils のインポートに失敗しました: {ie}\")\n",
    "             raise ie\n",
    "        if 'config_path' not in globals():\n",
    "             # config_path が未定義の場合、環境に応じて再設定\n",
    "             if IN_COLAB:\n",
    "                 config_filename_vis2 = 'config_for_google_colab.yaml'\n",
    "             else:\n",
    "                 config_filename_vis2 = 'config.yaml'\n",
    "             config_path = os.path.join(project_dir, 'configs', config_filename_vis2)\n",
    "             print(f\"警告: 'config_path' が未定義でした。'{config_path}' を使用します。\")\n",
    "        try:\n",
    "            config = load_config(config_path)\n",
    "        except FileNotFoundError as fe:\n",
    "            print(f\"設定ファイルが見つかりません: {fe}\")\n",
    "            raise fe\n",
    "        except yaml.YAMLError as ye:\n",
    "            print(f\"設定ファイルの解析エラー: {ye}\")\n",
    "            raise ye\n",
    "\n",
    "    # config からクラス名、平均、標準偏差を取得、なければデフォルト値\n",
    "    class_names = config.get('class_names', ['Class 0', 'Class 1', 'Class 2'])\n",
    "    mean = config.get('dataset_mean', [0.485, 0.456, 0.406])\n",
    "    std = config.get('dataset_std', [0.229, 0.224, 0.225])\n",
    "    print(f\"クラス名: {class_names}\")\n",
    "    print(f\"データセット平均: {mean}, 標準偏差: {std}\")\n",
    "\n",
    "    # データローダーからランダムに1バッチ取得\n",
    "    # data_module がロードされていることを確認\n",
    "    if 'data_module' not in globals():\n",
    "         raise NameError(\"data_module が定義されていません。前のセルを実行してください。\")\n",
    "    try:\n",
    "        test_loader = data_module.test_dataloader()\n",
    "        images, labels = next(iter(test_loader))\n",
    "        print(f\"テストローダーからバッチを取得しました。画像形状: {images.shape}, ラベル形状: {labels.shape}\")\n",
    "    except StopIteration:\n",
    "        print(\"エラー: テストデータローダーが空です。\")\n",
    "        # データがない場合は処理を中断\n",
    "        raise StopIteration(\"テストデータがありません\")\n",
    "    except Exception as dl_err: # DataLoaderに関する他のエラー\n",
    "        print(f\"データローダーからのバッチ取得中にエラー: {dl_err}\")\n",
    "        raise dl_err\n",
    "\n",
    "    # モデルを評価モードに設定\n",
    "    # model がロードされていることを確認\n",
    "    if 'model' not in globals():\n",
    "        raise NameError(\"model が定義されていません。前のセルを実行してください。\")\n",
    "    model.eval()\n",
    "    print(\"モデルを評価モードに設定しました。\")\n",
    "\n",
    "    # GPUが利用可能ならモデルとデータをGPUへ移動\n",
    "    # config から force_gpu を取得、なければデフォルト False\n",
    "    use_gpu = config.get('force_gpu', False) and torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_gpu else \"cpu\")\n",
    "    print(f\"使用デバイス: {device}\")\n",
    "    try:\n",
    "        model.to(device)\n",
    "        images = images.to(device)\n",
    "    except Exception as device_err:\n",
    "        print(f\"モデルまたはデータのデバイス転送中にエラー: {device_err}\")\n",
    "        raise device_err\n",
    "\n",
    "    # 予測実行\n",
    "    print(\"予測を実行します...\")\n",
    "    with torch.no_grad():\n",
    "        try:\n",
    "            # --- 修正箇所 ---\n",
    "            # model(images) の戻り値が logits のみであると仮定して修正\n",
    "            logits = model(images)\n",
    "            # reasoning_soft は削除\n",
    "            # --- 修正箇所ここまで ---\n",
    "\n",
    "            # 結果をCPUに戻してから計算（メモリ節約とNumPy変換のため）\n",
    "            logits = logits.cpu()\n",
    "            probs = torch.nn.functional.softmax(logits, dim=1)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            print(\"予測が完了しました。\")\n",
    "        except Exception as pred_err:\n",
    "            print(f\"モデルのフォワードパス実行中にエラー: {pred_err}\")\n",
    "            raise pred_err # エラーを再発生させてトレースバックを表示\n",
    "\n",
    "    # 結果の可視化\n",
    "    print(\"結果を可視化します...\")\n",
    "    # 正規化解除のための変換\n",
    "    try:\n",
    "        inv_normalize = transforms.Normalize(\n",
    "            mean=[-m/s for m, s in zip(mean, std)],\n",
    "            std=[1/s for s in std]\n",
    "        )\n",
    "    except ZeroDivisionError:\n",
    "        print(\"エラー: 標準偏差にゼロが含まれています。設定ファイルを確認してください。\")\n",
    "        raise ZeroDivisionError(\"標準偏差がゼロです\")\n",
    "\n",
    "    # 表示する画像数を決定 (最大8枚)\n",
    "    num_images_to_show = min(8, len(images))\n",
    "    if num_images_to_show == 0:\n",
    "        print(\"表示する画像がありません。\")\n",
    "    else:\n",
    "        # 描画領域のサイズ調整 (4列表示を想定)\n",
    "        num_rows = (num_images_to_show + 3) // 4\n",
    "        plt.figure(figsize=(16, 4 * num_rows)) # 横幅を少し広げる\n",
    "\n",
    "        # バッチの先頭から表示\n",
    "        indices = range(num_images_to_show)\n",
    "\n",
    "        for i, idx in enumerate(indices):\n",
    "            plt.subplot(num_rows, 4, i + 1)\n",
    "            # 画像をCPUに戻し、正規化を解除して表示用に次元を並び替え\n",
    "            img_tensor = images[idx].cpu() # 元のテンソルをCPUへ\n",
    "            try:\n",
    "                img = inv_normalize(img_tensor).permute(1, 2, 0).numpy()\n",
    "            except Exception as norm_err:\n",
    "                print(f\"画像の正規化解除または次元並び替え中にエラー: {norm_err}\")\n",
    "                # エラーが発生した画像はスキップ\n",
    "                plt.title(\"表示エラー\")\n",
    "                plt.axis('off')\n",
    "                continue\n",
    "\n",
    "            # 値を0-1の範囲にクリップ (正規化解除で範囲外になる可能性)\n",
    "            img = np.clip(img, 0, 1)\n",
    "            plt.imshow(img)\n",
    "\n",
    "            # ラベルと予測を取得\n",
    "            true_label_idx = labels[idx].item()\n",
    "            pred_label_idx = preds[idx].item()\n",
    "\n",
    "            # クラス名リスト外のインデックスアクセスを防ぐ\n",
    "            true_label_name = class_names[true_label_idx] if 0 <= true_label_idx < len(class_names) else f\"Unknown({true_label_idx})\"\n",
    "            pred_label_name = class_names[pred_label_idx] if 0 <= pred_label_idx < len(class_names) else f\"Unknown({pred_label_idx})\"\n",
    "\n",
    "            # タイトルに真ラベル、予測ラベル、予測確率を表示\n",
    "            plt.title(f\"True: {true_label_name}\\nPred: {pred_label_name} (Prob: {probs[idx][pred_label_idx]:.2f})\")\n",
    "            plt.axis('off') # 軸を非表示に\n",
    "\n",
    "        plt.tight_layout() # サブプロット間のスペースを調整\n",
    "        plt.show()\n",
    "        print(\"可視化が完了しました。\")\n",
    "\n",
    "# NameError は model, data_module, config_path, config が未定義の場合\n",
    "# FileNotFoundError は設定ファイルが見つからない場合（configロード時）\n",
    "# KeyError は config 辞書に必要なキーがない場合\n",
    "# AttributeError はオブジェクトに必要な属性がない場合（例: model.eval()）\n",
    "# StopIteration はデータローダーが空の場合\n",
    "# ZeroDivisionError は標準偏差がゼロの場合\n",
    "except (NameError, FileNotFoundError, KeyError, AttributeError, StopIteration, ZeroDivisionError) as e:\n",
    "     print(f\"可視化に必要な変数、設定、またはデータが見つからないか、アクセスできませんでした: {e}\")\n",
    "# 広範な例外捕捉は避ける\n",
    "except Exception as e: # より具体的な例外を捕捉することが望ましい\n",
    "    print(f\"予測結果の可視化中に予期せぬエラーが発生しました: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "64S2RnsBSvyw"
   },
   "source": [
    "## 混同行列の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kOSIqLFySvyw"
   },
   "outputs": [],
   "source": [
    "# テストデータセット全体での混同行列を表示\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "try:\n",
    "    # 設定ファイルからクラス名を取得\n",
    "    # config がロードされていることを確認\n",
    "    if 'config' not in globals():\n",
    "        # config がなければロードを試みる\n",
    "        print(\"警告: 'config' が未定義です。ロードを試みます...\")\n",
    "        configs_dir_cm = os.path.join(project_dir, 'configs') # project_dir は最初のセルで定義済みのはず\n",
    "        if configs_dir_cm not in sys.path:\n",
    "             sys.path.insert(0, configs_dir_cm)\n",
    "        try:\n",
    "            from config_utils import load_config\n",
    "        except ImportError as ie:\n",
    "             print(f\"config_utils のインポートに失敗しました: {ie}\")\n",
    "             raise ie\n",
    "        if 'config_path' not in globals():\n",
    "             # config_path が未定義の場合、環境に応じて再設定\n",
    "             if IN_COLAB:\n",
    "                 config_filename_cm = 'config_for_google_colab.yaml'\n",
    "             else:\n",
    "                 config_filename_cm = 'config.yaml'\n",
    "             config_path = os.path.join(project_dir, 'configs', config_filename_cm)\n",
    "             print(f\"警告: 'config_path' が未定義でした。'{config_path}' を使用します。\")\n",
    "        try:\n",
    "            config = load_config(config_path)\n",
    "        except FileNotFoundError as fe:\n",
    "            print(f\"設定ファイルが見つかりません: {fe}\")\n",
    "            raise fe\n",
    "        except yaml.YAMLError as ye:\n",
    "            print(f\"設定ファイルの解析エラー: {ye}\")\n",
    "            raise ye\n",
    "\n",
    "    # config からクラス名を取得、なければデフォルト値\n",
    "    class_names = config.get('class_names', ['Sell', 'Buy', 'Hold'])\n",
    "    print(f\"クラス名: {class_names}\")\n",
    "\n",
    "    # すべてのテストデータでの予測を収集するためのリスト\n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "\n",
    "    # モデルを評価モードに\n",
    "    # model がロードされていることを確認\n",
    "    if 'model' not in globals():\n",
    "        raise NameError(\"model が定義されていません。前のセルを実行してください。\")\n",
    "    model.eval()\n",
    "    print(\"モデルを評価モードに設定しました。\")\n",
    "\n",
    "    # GPUが利用可能ならモデルをGPUへ\n",
    "    # config から force_gpu を取得、なければデフォルト False\n",
    "    use_gpu_cm = config.get('force_gpu', False) and torch.cuda.is_available()\n",
    "    device_cm = torch.device(\"cuda\" if use_gpu_cm else \"cpu\")\n",
    "    print(f\"使用デバイス: {device_cm}\")\n",
    "    try:\n",
    "        model.to(device_cm)\n",
    "    except Exception as device_err_cm:\n",
    "        print(f\"モデルのデバイス転送中にエラー: {device_err_cm}\")\n",
    "        raise device_err_cm\n",
    "\n",
    "    print(\"テストデータ全体で予測を収集しています...\")\n",
    "    # data_module がロードされていることを確認\n",
    "    if 'data_module' not in globals():\n",
    "        raise NameError(\"data_module が定義されていません。前のセルを実行してください。\")\n",
    "\n",
    "    try:\n",
    "        test_loader_cm = data_module.test_dataloader()\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader_cm:\n",
    "                images, labels = batch\n",
    "                # データを適切なデバイスへ\n",
    "                try:\n",
    "                    images = images.to(device_cm)\n",
    "                except Exception as batch_device_err:\n",
    "                    print(f\"バッチデータのデバイス転送中にエラー: {batch_device_err}\")\n",
    "                    # このバッチをスキップするか、エラーを発生させるか検討\n",
    "                    continue # スキップする場合\n",
    "\n",
    "                # 予測実行\n",
    "                try:\n",
    "                    # --- 修正箇所 ---\n",
    "                    # model(images) の戻り値が logits のみであると仮定して修正\n",
    "                    logits = model(images) # reasoning_soft は削除\n",
    "                    # --- 修正箇所ここまで ---\n",
    "                    preds = torch.argmax(logits, dim=1)\n",
    "                except Exception as batch_pred_err:\n",
    "                    print(f\"バッチ予測中にエラー: {batch_pred_err}\")\n",
    "                    # このバッチをスキップするか、エラーを発生させるか検討\n",
    "                    continue # スキップする場合\n",
    "\n",
    "                # 結果をCPUに集める (NumPy変換のため)\n",
    "                true_labels.extend(labels.cpu().numpy())\n",
    "                pred_labels.extend(preds.cpu().numpy())\n",
    "    except StopIteration:\n",
    "         print(\"警告: テストデータローダーが空でした。混同行列は計算できません。\")\n",
    "         # データがない場合は以降の処理をスキップ\n",
    "         # raise StopIteration(\"テストデータがありません\") # またはここで終了\n",
    "    except Exception as collect_err:\n",
    "         print(f\"予測収集中にエラーが発生しました: {collect_err}\")\n",
    "         raise collect_err\n",
    "\n",
    "    # 予測が収集できた場合のみ混同行列を計算・表示\n",
    "    if true_labels and pred_labels:\n",
    "        print(\"予測の収集が完了しました。混同行列を計算・表示します。\")\n",
    "\n",
    "        # 混同行列の計算\n",
    "        try:\n",
    "            cm = confusion_matrix(true_labels, pred_labels)\n",
    "        except ValueError as cm_err:\n",
    "             print(f\"混同行列の計算中にエラー: {cm_err}\")\n",
    "             # ラベルの不一致などが考えられる\n",
    "             raise cm_err\n",
    "\n",
    "        # 混同行列の可視化\n",
    "        plt.figure(figsize=(8, 6)) # サイズを少し調整\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                    xticklabels=class_names, yticklabels=class_names)\n",
    "        plt.xlabel('Predicted Label') # ラベル名を修正\n",
    "        plt.ylabel('True Label')     # ラベル名を修正\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.show()\n",
    "\n",
    "        # 詳細な分類レポートを表示\n",
    "        print(\"\\n分類レポート:\")\n",
    "        try:\n",
    "            # zero_division=0 を追加して、ゼロ除算が発生した場合の警告を抑制し、値を0にする\n",
    "            report = classification_report(true_labels, pred_labels, target_names=class_names, digits=4, zero_division=0)\n",
    "            print(report)\n",
    "        except ValueError as report_err:\n",
    "             print(f\"分類レポートの生成中にエラー: {report_err}\")\n",
    "             # ラベルの不一致などが考えられる\n",
    "             raise report_err\n",
    "    else:\n",
    "        print(\"予測データが収集されなかったため、混同行列の計算と表示をスキップしました。\")\n",
    "\n",
    "\n",
    "# NameError は model, data_module, config_path, config が未定義の場合\n",
    "# FileNotFoundError は設定ファイルが見つからない場合（configロード時）\n",
    "# KeyError は config 辞書に必要なキーがない場合\n",
    "# ImportError はモジュールインポート失敗時\n",
    "# StopIteration はデータローダーが空の場合\n",
    "except (NameError, FileNotFoundError, KeyError, ImportError, StopIteration) as e:\n",
    "     print(f\"混同行列の計算に必要な変数、設定、またはデータが見つかりません: {e}\")\n",
    "# 広範な例外捕捉は避ける\n",
    "except Exception as e: # より具体的な例外を捕捉することが望ましい\n",
    "    print(f\"混同行列の計算または表示中に予期せぬエラーが発生しました: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
